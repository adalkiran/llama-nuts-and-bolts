package model

import (
	"fmt"
	"math"
	"os"
	"reflect"
	"testing"

	"github.com/adalkiran/llama-nuts-and-bolts/src/common"
	"github.com/adalkiran/llama-nuts-and-bolts/src/dtype"
	"github.com/adalkiran/llama-nuts-and-bolts/src/ml"
)

/*
	This simulation was added to ensure all steps are done correctly
	(until only first attention layer).
*/

func testTransformer_Prepare(t *testing.T, actualInputTensor *ml.Tensor, actualFreqsCis *ml.Tensor, actualMask *ml.Tensor) {
	expectedInputTensorSize := []int{5, 4096}
	// Shortened form as corresponding indices [0, 1, 2, 4093, 4094, 4095]
	expectedInputTensorShortened := [][]float32{
		{0.0019, -0.0034, 0.0004 /*...,*/, -0.0083, 0.0026, -0.0039},
		{0.0381, -0.0007, 0.0069 /*...,*/, -0.0168, 0.0024, 0.0157},
		{-0.0150, -0.0162, 0.0110 /*...,*/, 0.0082, -0.0283, 0.0049},
		{-0.0032, -0.0100, -0.0110 /*...,*/, -0.0033, -0.0038, -0.0117},
		{-0.0054, 0.0012, 0.0083 /*...,*/, 0.0112, -0.0043, -0.0077},
	}

	expectedFreqsCisSize := []int{5, 64}

	expectedMaskSize := []int{5, 5}
	negInf := float32(math.Inf(-1))
	expectedMask := [][]float32{
		{0, negInf, negInf, negInf, negInf},
		{0, 0, negInf, negInf, negInf},
		{0, 0, 0, negInf, negInf},
		{0, 0, 0, 0, negInf},
		{0, 0, 0, 0, 0},
	}

	if err := ml.CompareTestTensorSkippable(false, expectedInputTensorShortened, expectedInputTensorSize, actualInputTensor, common.THRESHOLD_F32, true); err != nil {
		t.Error(err)
	}

	if !reflect.DeepEqual(expectedFreqsCisSize, actualFreqsCis.Size) {
		t.Errorf("expected size %v, but got %v", expectedFreqsCisSize, actualFreqsCis.Size)
	}

	if err := ml.CompareTestTensorSkippable(false, expectedMask, expectedMaskSize, actualMask, common.THRESHOLD_F32, false); err != nil {
		t.Error(err)
	}
}

func testTransformerBlock_AttnNorm_Forward(t *testing.T, skipCompareTestTensor bool, transformerBlock *LlamaTransformerBlock, x *ml.Tensor) *ml.Tensor {
	/*
		normalizedX, err := ltb.attn_norm.Forward(context, x)
	*/
	expectedAttnNormPartSize := []int{5, 4096}
	expectedAttnNormPart := [][]float32{
		{0.2271, -0.4113, 0.0486 /*...,*/, -1.0125, 0.3145, -0.4802},
		{2.2847, -0.0412, 0.4119 /*...,*/, -1.0106, 0.1437, 0.9447},
		{-1.2023, -1.3054, 0.8833 /*...,*/, 0.6625, -2.2770, 0.3926},
		{-0.2195, -0.6924, -0.7599 /*...,*/, -0.2280, -0.2596, -0.8063},
		{-0.5375, 0.1223, 0.8214 /*...,*/, 1.1053, -0.4288, -0.7610},
	}

	expectedAttnNormalizedXSize := []int{5, 4096}
	expectedAttnNormalizedX := [][]float32{
		{6.7444e-03, -5.6152e-03, 9.5844e-05 /*...,*/, -1.0437e-02, 3.4485e-03, -2.9144e-03},
		{6.7871e-02, -5.6076e-04, 8.1253e-04 /*...,*/, -1.0315e-02, 1.5793e-03, 5.7373e-03},
		{-3.5645e-02, -1.7700e-02, 1.7395e-03 /*...,*/, 6.8054e-03, -2.5024e-02, 2.3804e-03},
		{-6.5308e-03, -9.3994e-03, -1.5030e-03 /*...,*/, -2.3346e-03, -2.8534e-03, -4.8828e-03},
		{-1.5991e-02, 1.6632e-03, 1.6174e-03 /*...,*/, 1.1292e-02, -4.7302e-03, -4.6387e-03},
	}

	actualAttnNormPart, err := transformerBlock.attn_norm.doNormalization(x)
	if err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedAttnNormPart, expectedAttnNormPartSize, actualAttnNormPart, 2*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	actualAttnNormalizedX, err := ml.MultiplyElementwise(actualAttnNormPart, transformerBlock.attn_norm.weights)
	if err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedAttnNormalizedX, expectedAttnNormalizedXSize, actualAttnNormalizedX, common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}
	return actualAttnNormalizedX
}

func testTransformerBlock_Attention_Forward(t *testing.T, skipCompareTestTensor bool, context *InferenceContext, attention *LlamaAttention, x *ml.Tensor, startPos int, freqsCis *ml.Tensor, mask *ml.Tensor) *ml.Tensor {
	expectedXqSize := []int{5, 4096}
	expectedXq := [][]float32{
		{0.1157, -0.4805, -0.4180 /*...,*/, 0.6250, -0.1670, 0.1602},
		{0.2598, -1.7734, -1.2266 /*..., */, 0.3789, -0.1729, -0.5195},
		{0.0747, -1.6172, -0.9336 /*...,*/, 0.3652, 0.0255, -0.1855},
		{0.1953, -1.8047, -1.1953 /*...,*/, 0.1611, -0.0103, -0.2363},
		{0.0112, -1.2500, -0.5391 /*...,*/, 0.1689, 0.1807, 0.0957},
	}

	expectedXkSize := []int{5, 4096}
	expectedXk := [][]float32{
		{-0.4512, -0.1523, -0.0170 /*...,*/, 0.2158, -0.3340, 0.2773},
		{-0.4258, 0.6836, 0.5156 /*...,*/, -0.6406, 0.7188, 0.3633},
		{-0.4824, 0.2930, 0.2285 /*..., */, 0.8438, -1.0469, -0.1099},
		{0.2051, -0.1377, -0.3711 /*...,*/, -0.5156, 0.6289, 0.1582},
		{-0.1514, -0.3613, -0.3457 /*...,*/, 0.9844, -0.9492, -0.2480},
	}

	expectedXvSize := []int{5, 4096}
	expectedXv := [][]float32{
		{-0.0060, -0.0064, 0.0056 /*...,*/, 0.0015, -0.0007, -0.0014},
		{0.0004, -0.0088, -0.0033 /* ...,*/, 0.0014, -0.0098, 0.0042},
		{0.0077, -0.0022, 0.0038 /* ...,*/, -0.0013, 0.0211, 0.0021},
		{-0.0008, -0.0053, 0.0113 /*...,*/, 0.0008, -0.0024, -0.0041},
		{0.0032, 0.0017, 0.0006 /*...,*/, -0.0003, 0.0056, 0.0035},
	}

	sequenceLength := x.Size[0]

	// lat.attn_wq: [out_features, in_features] -> shape: [4096 4096] -> [N_Heads * HeadDim, Dim]
	actualXq, err := ml.LinearTransformation(x, attention.attn_wq)
	if err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXq, expectedXqSize, actualXq, 2*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	// lat.attn_wk: [out_features, in_features] -> shape: [4096 4096] -> [N_KVHeads * HeadDim, Dim]
	actualXk, err := ml.LinearTransformation(x, attention.attn_wk)
	if err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXk, expectedXkSize, actualXk, 2*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	// lat.attn_wv: [out_features, in_features] -> shape: [4096 4096] -> [N_KVHeads * HeadDim, Dim]
	actualXv, err := ml.LinearTransformation(x, attention.attn_wv)
	if err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXv, expectedXvSize, actualXv, 2*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	/*
		Do reshapings
	*/

	expectedXqRsSize := []int{5, 32, 128}
	expectedXqRs := [][][]float32{
		{
			{0.1157, -0.4805, -0.4180 /*...,*/, 1.6875, 0.6250, -0.3145},
			{-0.1426, -1.0078, 0.2930 /*..., */, -0.6953, 0.0913, 0.5508},
			{-0.0281, 0.1206, 0.3184 /*..., */, 0.3574, -0.3418, 0.3496},
			/*...,*/
			{0.6992, 1.4062, -1.6094 /*...,*/, 0.5352, -0.2256, 1.2891},
			{0.7344, 1.9141, 1.0312 /*...,*/, 0.5234, -0.3809, 0.4863},
			{-1.3672, 0.7383, 1.3828 /*...,*/, 0.6250, -0.1670, 0.1602},
		},
		{
			{0.2598, -1.7734, -1.2266 /*...,*/, 0.5273, -1.1094, -0.7930},
			{0.0859, 0.0374, 0.1377 /*..., */, -0.9297, 0.1631, 0.5664},
			{0.5664, 0.5977, 0.0122 /*..., */, 0.3223, -0.2773, 0.3516},
			/*...,*/
			{0.5078, 2.9375, -2.4844 /* ..., */, 0.9219, -1.4141, 2.1094},
			{0.8242, 2.4531, 2.0469 /*...,*/, 0.5547, -0.4023, 0.5703},
			{-0.9297, 0.4766, -0.2754 /*...,*/, 0.3789, -0.1729, -0.5195},
		},
		{
			{0.0747, -1.6172, -0.9336 /* ..., */, 0.2871, -0.8203, -0.7422},
			{0.3301, -0.1230, 0.1807 /* ...,*/, -0.1309, -0.6719, -0.1494},
			{-0.5195, 0.8438, -0.7734 /* ...,*/, -0.1084, 0.0903, -0.0830},
			/*...,*/
			{0.4414, 1.3047, -1.0859 /* ..., */, 0.7578, -0.3613, 1.1875},
			{0.5820, 2.6094, 2.1250 /* ..., */, 0.6172, -0.4570, 0.6367},
			{-1.7734, 0.4219, -1.1250 /* ..., */, 0.3652, 0.0255, -0.1855},
		},
		{
			{0.1953, -1.8047, -1.1953 /* ...,*/, 0.7383, -1.0000, -1.0156},
			{0.0996, -0.0767, 0.0513 /* ..., */, -0.5312, -0.0591, 0.2129},
			{0.4375, 0.1270, 0.2285 /* ...,*/, 0.0737, -0.0613, 0.0986},
			/*...,*/
			{0.5195, 1.8828, -2.0469 /* ...,*/, 0.7461, -0.7031, 1.5938},
			{0.8320, 2.6094, 1.9922 /* ..., */, 0.6016, -0.4414, 0.6211},
			{-1.2812, 0.4707, -0.5156 /* ..., */, 0.1611, -0.0103, -0.2363},
		},
		{
			{0.0112, -1.2500, -0.5391 /* ..., */, 0.3301, -0.9062, -0.7461},
			{0.4512, -0.3379, 0.1299 /*...,  */, 0.1914, -0.9492, -0.3809},
			{-0.6211, 0.6094, -0.7656 /* ..., */, -0.2754, 0.2207, -0.2461},
			/* ...,*/
			{0.3516, 0.6523, -0.5547 /*  ..., */, 0.5547, -0.1299, 0.7070},
			{0.5508, 2.6562, 2.0156 /* ...,*/, 0.6289, -0.4688, 0.6445},
			{-1.9844, 0.4141, -1.2734 /* ...,*/, 0.1689, 0.1807, 0.0957},
		},
	}

	expectedXkRsSize := []int{5, 32, 128}
	expectedXkRs := [][][]float32{
		{
			{-0.4512, -0.1523, -0.0170 /*...,*/, -0.0238, -0.6211, -0.1260},
			{1.3516, -0.6094, 1.0781 /*...,*/, -0.3047, 0.0752, 0.4785},
			{0.0020, 0.3535, -0.2578 /*...,*/, 0.4980, -0.8320, 0.7617},
			/*...,*/
			{0.0247, -0.0693, -0.0049 /*...,*/, 0.9648, -0.4316, -0.4023},
			{0.1729, -0.7109, -0.5391 /*...,*/, 0.1367, -0.1855, 0.1406},
			{-0.4512, 0.1348, 1.2266 /*...,*/, 0.2158, -0.3340, 0.2773},
		},
		{
			{-0.4258, 0.6836, 0.5156 /*...,*/, -0.1240, 0.2754, 0.6055},
			{0.8867, -0.3125, 0.5547 /*...,*/, 0.3418, 0.2695, -0.2266},
			{-0.1836, 0.2852, -0.4941 /*..., */, -0.5156, 0.5898, -0.4668},
			/* ...,*/
			{-0.0615, -0.1543, 0.0630 /*...,*/, 0.5898, -0.1992, -0.1113},
			{0.2520, 0.2832, -0.2139 /*...,*/, -0.1226, 0.2383, -0.1182},
			{-1.0703, -0.2158, -0.8320 /*...,*/, -0.6406, 0.7188, 0.3633},
		},
		{
			{-0.4824, 0.2930, 0.2285 /*...,*/, -0.2520, 0.1758, 0.3535},
			{0.5977, 0.5234, 0.7812 /*...,*/, 0.2559, -0.1982, -0.6914},
			{-0.4004, -0.4609, 0.0496 /*...,*/, 1.8359, -1.7812, 1.6953},
			/* ...,*/
			{-1.2031, 0.3594, -0.2715 /*...,*/, -0.7148, 1.3750, -1.0703},
			{-0.4590, -0.1748, -0.3145 /*...,*/, 0.1357, -0.3457, 0.1387},
			{0.1157, -0.0874, -0.0542 /*...,*/, 0.8438, -1.0469, -0.1099},
		},
		{
			{0.2051, -0.1377, -0.3711 /*...,*/, 0.0244, -0.1035, 0.0479},
			{0.9414, 0.0113, 0.7305 /*...,*/, -0.0496, 0.3457, 0.4316},
			{0.0566, 0.3809, -0.2471 /*...,*/, -0.7852, 0.7891, -0.6797},
			/* ...,*/
			{-0.3301, 0.0918, -0.0408 /*...,*/, 0.0791, 0.3047, -0.5469},
			{0.2266, -0.0239, -0.4453 /*...,*/, -0.2559, 0.3516, -0.2520},
			{-0.6328, -0.3828, -0.5000 /*...,*/, -0.5156, 0.6289, 0.1582},
		},
		{
			{-0.1514, -0.3613, -0.3457 /*...,*/, 0.2314, -0.1050, -0.1689},
			{0.5117, 0.8516, 0.9414 /*...,*/, 0.0466, -0.3086, -0.3418},
			{-0.2910, -0.3867, 0.1621 /*...,*/, 1.8047, -1.7031, 1.6484},
			/* ...,*/
			{-1.7266, 0.5273, -0.3926 /*...,*/, -1.0391, 1.9141, -1.3359},
			{-0.3926, -0.4316, -0.5898 /*...,*/, 0.0928, -0.3438, 0.0918},
			{0.2100, -0.0898, 0.0125 /*...,*/, 0.9844, -0.9492, -0.2480},
		},
	}

	expectedXvRsSize := []int{5, 32, 128}
	expectedXvRs := [][][]float32{
		{
			{-6.0425e-03, -6.3782e-03, 5.5847e-03 /*...,*/, 1.3809e-03,
				2.0264e-02, -5.5237e-03},
			{2.0599e-03, 4.0283e-03, -9.7046e-03 /*..., */, -4.7607e-03,
				6.9275e-03, -1.9043e-02},
			{-3.8605e-03, -6.4392e-03, 1.4221e-02 /*..., */, 5.0354e-03,
				-1.4648e-02, 6.9885e-03},
			/*...,*/
			{-5.9509e-04, -2.0752e-03, -1.5747e-02 /*...,*/, 2.0752e-02,
				9.4604e-03, -5.1880e-03},
			{4.3106e-04, 1.5503e-02, -1.0254e-02 /*...,*/, -8.6060e-03,
				-4.5166e-02, -2.5024e-02},
			{-3.9978e-03, -3.9368e-03, 4.6730e-04 /*...,*/, 1.4572e-03,
				-6.7139e-04, -1.4420e-03},
		},

		{
			{3.8719e-04, -8.7891e-03, -3.2806e-03 /*...,*/, 5.3406e-03,
				1.2131e-03, -6.1646e-03},
			{8.1539e-05, -9.0790e-04, 2.3956e-03 /*...,*/, 9.7046e-03,
				2.1057e-03, -3.3417e-03},
			{7.9956e-03, -6.7139e-03, -6.6757e-04 /*...,*/, 5.0354e-03,
				2.9449e-03, -3.7231e-03},
			/*  ...,*/
			{-1.0376e-02, 4.0283e-02, -6.9336e-02 /*...,*/, -9.7656e-02,
				-3.1494e-02, -2.0752e-02},
			{-6.5918e-03, 2.0386e-02, -6.9885e-03 /*...,*/, -6.9580e-03,
				7.9632e-05, -4.5776e-03},
			{2.9144e-03, 1.0498e-02, -9.3384e-03 /*...,*/, 1.4191e-03,
				-9.7656e-03, 4.1809e-03},
		},

		{{7.6904e-03, -2.2430e-03, 3.8452e-03 /*...,*/, 6.8054e-03,
			1.2512e-03, 2.6245e-03},
			{3.4332e-03, 1.0986e-03, 1.6708e-03 /*...,*/, -5.3101e-03,
				-2.9144e-03, -4.0283e-03},
			{-7.9956e-03, 5.7373e-03, 8.3618e-03 /*...,*/, 1.8921e-03,
				7.5073e-03, 6.9885e-03},
			/*...,*/
			{-1.4954e-03, -2.1362e-02, 3.1738e-02 /*...,*/, 1.7624e-03,
				-2.0752e-03, 1.6724e-02},
			{1.0498e-02, -4.1199e-03, -1.6632e-03 /*...,*/, 6.0730e-03,
				-5.2795e-03, 1.2512e-03},
			{6.6223e-03, -1.5503e-02, -4.6997e-03 /*...,*/, -1.2894e-03,
				2.1118e-02, 2.1210e-03},
		},

		{
			{-7.7057e-04, -5.3406e-03, 1.1292e-02 /*...,*/, -5.9814e-03,
				5.8746e-04, -2.7084e-04},
			{-7.4768e-03, 1.3733e-03, -3.0212e-03 /*...,*/, 2.1820e-03,
				6.9275e-03, 7.2327e-03},
			{-1.0147e-03, -8.3618e-03, 4.1199e-03 /*...,*/, -8.4229e-03,
				-9.3994e-03, -6.9580e-03},
			/*...,*/
			{-9.4604e-03, -5.7373e-02, 2.2278e-03 /*...,*/, -5.6396e-02,
				-1.0071e-02, 1.3367e-02},
			{3.6926e-03, -3.4332e-03, 2.9449e-03 /*...,*/, -1.0254e-02,
				-1.2878e-02, 3.1738e-03},
			{-4.2343e-04, 9.5749e-04, -8.3618e-03 /*...,*/, 7.9346e-04,
				-2.4261e-03, -4.1199e-03},
		},

		{
			{3.1586e-03, 1.7166e-03, 6.1035e-04 /*...,*/, 6.3782e-03,
				2.3193e-03, -9.2506e-05},
			{-5.4321e-03, 1.8082e-03, -6.9275e-03 /*...,*/, 1.4420e-03,
				-4.1504e-03, 2.6131e-04},
			{-2.6131e-04, 1.1444e-03, -3.2663e-05 /*...,*/, 1.2112e-04,
				5.2490e-03, -1.1597e-03},
			/* ...,*/
			{-8.8501e-03, -2.4414e-02, -3.0884e-02 /*...,*/, 2.1606e-02,
				-4.6387e-03, -2.1729e-02},
			{1.7853e-03, 3.9062e-03, -7.5150e-04 /*...,*/, -2.8610e-04,
				5.4626e-03, 1.2207e-03},
			{2.9449e-03, -1.0529e-03, -6.4697e-03 /*...,*/, -3.0136e-04,
				5.5847e-03, 3.4790e-03},
		},
	}

	if actualXq, err = actualXq.Reshape([]int{sequenceLength, attention.N_Heads, attention.HeadDim}); err != nil {
		t.Fatal(err)
	}

	if actualXk, err = actualXk.Reshape([]int{sequenceLength, attention.N_KVHeads, attention.HeadDim}); err != nil {
		t.Fatal(err)
	}

	if actualXv, err = actualXv.Reshape([]int{sequenceLength, attention.N_KVHeads, attention.HeadDim}); err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXqRs, expectedXqRsSize, actualXq, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXkRs, expectedXkRsSize, actualXk, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXvRs, expectedXvRsSize, actualXv, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	/*
		Apply rotary embeddings
	*/

	expectedXqRotarySize := []int{5, 32, 128}
	expectedXqRotary := [][][]float32{
		{
			{0.1157, -0.4805, -0.4180 /*...,*/, 1.6875, 0.6250, -0.3145},
			{-0.1426, -1.0078, 0.2930 /*...,*/, -0.6953, 0.0913, 0.5508},
			{-0.0281, 0.1206, 0.3184 /*...,*/, 0.3574, -0.3418, 0.3496},
			/*...,*/
			{0.6992, 1.4062, -1.6094 /*...,*/, 0.5352, -0.2256, 1.2891},
			{0.7344, 1.9141, 1.0312 /*...,*/, 0.5234, -0.3809, 0.4863},
			{-1.3672, 0.7383, 1.3828 /*...,*/, 0.6250, -0.1670, 0.1602},
		},
		{
			{1.6326, -0.7396, -2.1099 /*...,*/, 0.5273, -1.1093, -0.7931},
			{0.0150, 0.0925, -0.0737 /*...,*/, -0.9296, 0.1630, 0.5664},
			{-0.1969, 0.7995, -0.5068 /*...,*/, 0.3222, -0.2774, 0.3515},
			/*...,*/
			{-2.1974, 2.0144, -2.4071 /*...,*/, 0.9217, -1.4143, 2.1092},
			{-1.6189, 2.0190, 2.4747 /*...,*/, 0.5546, -0.4024, 0.5703},
			{-0.9033, -0.5248, -0.5399 /*...,*/, 0.3789, -0.1728, -0.5196},
		},
		{
			{1.4394, 0.7409, -1.3154 /*...,*/, 0.2870, -0.8201, -0.7424},
			{-0.0255, 0.3513, -0.0381 /*...,*/, -0.1309, -0.6718, -0.1496},
			{-0.5510, -0.8235, -0.4003 /*...,*/, -0.1084, 0.0904, -0.0830},
			/*...,*/
			{-1.3700, -0.1416, -0.1631 /*...,*/, 0.7577, -0.3616, 1.1874},
			{-2.6149, -0.5566, 1.0548 /*...,*/, 0.6171, -0.4572, 0.6366},
			{0.3544, -1.7881, -0.3477 /*...,*/, 0.3652, 0.0256, -0.1855},
		},
		{
			{0.0613, 1.8142 /*0.0732*/, 0.0314 /*...,*/, 0.7380, -0.9996, -1.0160},
			{-0.0878, 0.0899, -0.0848 /*...,*/, -0.5313, -0.0592, 0.2129},
			{-0.4510, -0.0639, -0.4249 /*...,*/, 0.0738, -0.0613, 0.0986},
			/*...,*/
			{-0.7800, -1.7907 /*1.3617*/, 1.3125 /*...,*/, 0.7455, -0.7037, 1.5935},
			{-1.1919, -2.4658 /*-0.9128*/, -0.8554 /*...,*/, 0.6014, -0.4416, 0.6209},
			{1.2020, -0.6468, 0.2008 /*...,*/, 0.1611, -0.0102, -0.2363},
		},
		{
			{-0.9533, 0.8086, 0.9146 /*...,*/, 0.3299, -0.9059, -0.7465},
			{-0.5506, -0.1206, -0.1950 /*...,*/, 0.1911, -0.9490, -0.3813},
			{0.8672, 0.0717, 0.9167 /*...,*/, -0.2753, 0.2208, -0.2460},
			/*...,*/
			{0.2639, -0.6925, 0.5549 /*...,*/, 0.5546, -0.1302, 0.7070},
			{1.6502, -2.1531, -2.3325 /*...,*/, 0.6287, -0.4690, 0.6443},
			{1.6104, 1.2311, 1.3737 /*...,*/, 0.1689, 0.1806, 0.0958},
		},
	}

	expectedXkRotarySize := []int{5, 32, 128}
	expectedXkRotary := [][][]float32{
		{{-4.5117e-01, -1.5234e-01, -1.6968e-02 /*...,*/, -2.3804e-02, -6.2109e-01, -1.2598e-01},
			{1.3516e+00, -6.0938e-01, 1.0781e+00 /*...,*/, -3.0469e-01, 7.5195e-02, 4.7852e-01},
			{2.0142e-03, 3.5352e-01, -2.5781e-01 /*...,*/, 4.9805e-01, -8.3203e-01, 7.6172e-01},
			/*...,*/
			{2.4658e-02, -6.9336e-02, -4.8523e-03 /*...,*/, 9.6484e-01, -4.3164e-01, -4.0234e-01},
			{1.7285e-01, -7.1094e-01, -5.3906e-01 /*...,*/, 1.3672e-01, -1.8555e-01, 1.4062e-01},
			{-4.5117e-01, 1.3477e-01, 1.2266e+00 /*...,*/, 2.1582e-01, -3.3398e-01, 2.7734e-01},
		},
		{
			{-8.0527e-01, 1.1065e-02, 4.6351e-01 /*...,*/, -1.2390e-01, 2.7532e-01, 6.0550e-01},
			{7.4206e-01, 5.7730e-01, 7.0305e-01 /*...,*/, 3.4175e-01, 2.6956e-01, -2.2653e-01},
			{-3.3915e-01, -4.1823e-04, -9.9972e-02 /*...,*/, -5.1559e-01, 5.8990e-01, -4.6673e-01},
			/*...,*/
			{9.6595e-02, -1.3514e-01, 7.3727e-02 /*...,*/, 5.8992e-01, -1.9921e-01, -1.1135e-01},
			{-1.0218e-01, 3.6503e-01, 4.3570e-01 /*...,*/, -1.2253e-01, 2.3829e-01, -1.1814e-01},
			{-3.9669e-01, -1.0172e+00, -9.0655e-01 /*...,*/, -6.4074e-01, 7.1871e-01, 3.6336e-01},
		},
		{
			{-6.5637e-02, -5.6058e-01, 2.8402e-02 /*...,*/, -2.5194e-01, 1.7570e-01, 3.5356e-01},
			{-7.2467e-01, 3.2562e-01, -4.3186e-01 /*...,*/, 2.5575e-01, -1.9808e-01, -6.9145e-01},
			{5.8575e-01, -1.7226e-01, 3.1014e-01 /*...,*/, 1.8356e+00, -1.7816e+00, 1.6949e+00},
			/*...,*/
			{1.7390e-01, -1.2436e+00, 8.8023e-01 /*...,*/, -7.1466e-01, 1.3752e+00, -1.0700e+00},
			{3.4995e-01, -3.4461e-01, 7.9073e-01 /*...,*/, 1.3564e-01, -3.4574e-01, 1.3859e-01},
			{3.1317e-02, 1.4160e-01, -1.0119e-01 /*...,*/, 8.4412e-01, -1.0468e+00, -1.1011e-01},
		},
		{
			{-1.8359e-01, 1.6526e-01, 2.4282e-01 /*...,*/, 2.4401e-02, -1.0353e-01, 4.7816e-02},
			{-9.3358e-01, 1.2167e-01, -4.7560e-01 /*...,*/, -4.9502e-02, 3.4555e-01, 4.3176e-01},
			{-1.0982e-01, -3.6905e-01, 3.1248e-01 /*...,*/, -7.8495e-01, 7.8930e-01, -6.7941e-01},
			/*...,*/
			{3.1382e-01, -1.3746e-01, 1.3997e-01 /*...,*/, 7.9395e-02, 3.0488e-01, -5.4677e-01},
			{-2.2092e-01, 5.5659e-02, 6.1045e-01 /*...,*/, -2.5573e-01, 3.5165e-01, -2.5183e-01},
			{6.8050e-01, 2.8968e-01, 2.7635e-01 /*...,*/, -5.1596e-01, 6.2885e-01, 1.5842e-01},
		},
		{
			{-1.7451e-01, 3.5073e-01, 4.0832e-01 /*...,*/, 2.3123e-01, -1.0490e-01, -1.6899e-01},
			{3.0998e-01, -9.4389e-01, -7.0613e-01 /*...,*/, 4.6574e-02, -3.0844e-01, -3.4194e-01},
			{-1.0245e-01, 4.7302e-01, -2.3047e-01 /*...,*/, 1.8040e+00, -1.7039e+00, 1.6477e+00},
			/*...,*/
			{1.5277e+00, 9.6197e-01, -4.5795e-02 /*...,*/, -1.0385e+00, 1.9147e+00, -1.3351e+00},
			{-7.0061e-02, 5.7924e-01, 3.7267e-01 /*...,*/, 9.2590e-02, -3.4379e-01, 9.1638e-02},
			{-2.0523e-01, -1.0017e-01, 3.9832e-03 /*...,*/, 9.8505e-01, -9.4910e-01, -2.4849e-01},
		},
	}

	if actualXq, actualXk, err = applyRotaryEmbeddings(actualXq, actualXk, freqsCis); err != nil {
		return nil
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXqRotary, expectedXqRotarySize, actualXq, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXkRotary, expectedXkRotarySize, actualXk, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	/*
		Update KV cache
	*/

	context.CacheK.SetSlice([]int{startPos}, []int{startPos + sequenceLength}, actualXk)
	context.CacheV.SetSlice([]int{startPos}, []int{startPos + sequenceLength}, actualXv)

	/*
		Retrieve cached KV so far
	*/

	actualKeys, err := context.CacheK.Slice([]int{0}, []int{startPos + sequenceLength})
	if err != nil {
		t.Fatal(err)
	}
	actualValues, err := context.CacheV.Slice([]int{0}, []int{startPos + sequenceLength})
	if err != nil {
		t.Fatal(err)
	}

	/*
		Repeat k/v heads if N_KVHeads < N_Heads
	*/

	N_Rep := 1 // no repetition is needed for 7B model

	if actualKeys, err = attentionRepeatKV(actualKeys, N_Rep); err != nil { // shape=[5, 32, 128] (cacheLen + sequenceLength, N_Heads, HeadDim)
		t.Fatal(err)
	}
	if actualValues, err = attentionRepeatKV(actualValues, N_Rep); err != nil { // shape=[5, 32, 128] (cacheLen + sequenceLength, N_Heads, HeadDim)
		t.Fatal(err)
	}

	if startPos == 0 {
		// For startPos=0 and N_Rep=1 case, retrieved "keys" and "values" variables from KV Cache are same with "actualXk" and "actualXV" values
		if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXkRotary, expectedXkRotarySize, actualXk, 4*common.THRESHOLD_BF16, true); err != nil {
			t.Fatal(err)
		}

		if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXvRs, expectedXvRsSize, actualXv, 4*common.THRESHOLD_BF16, true); err != nil {
			t.Fatal(err)
		}
	}

	/*
		Do transposes
	*/

	expectedXqTransposeSize := []int{32, 5, 128}
	expectedXqTranspose := [][][]float32{
		{
			{0.1157, -0.4805, -0.4180 /*...,*/, 1.6875, 0.6250, -0.3145},
			{1.6328, -0.7383, -2.1094 /*...,*/, 0.5273, -1.1094, -0.7930},
			{1.4375, 0.7422, -1.3125 /*...,*/, 0.2871, -0.8203, -0.7422},
			{0.0613, 1.8125 /*0.0732*/, 0.0314 /*...,*/, 0.7383, -1.0000, -1.0156},
			{-0.9531, 0.8086, 0.9141 /*...,*/, 0.3301, -0.9062, -0.7461},
		},
		{
			{-0.1426, -1.0078, 0.2930 /*...,*/, -0.6953, 0.0913, 0.5508},
			{0.0150, 0.0923, -0.0737 /*...,*/, -0.9297, 0.1631, 0.5664},
			{-0.0255, 0.3516, -0.0381 /*...,*/, -0.1309, -0.6719, -0.1494},
			{-0.0879, 0.0898, -0.0850 /*...,*/, -0.5312, -0.0591, 0.2129},
			{-0.5508, -0.1206, -0.1953 /*...,*/, 0.1914, -0.9492, -0.3809},
		},
		{
			{-0.0281, 0.1206, 0.3184 /*...,*/, 0.3574, -0.3418, 0.3496},
			{-0.1973, 0.8008, -0.5078 /*...,*/, 0.3223, -0.2773, 0.3516},
			{-0.5508, -0.8242, -0.4004 /*...,*/, -0.1084, 0.0903, -0.0830},
			{-0.4512, -0.0640, -0.4258 /*...,*/, 0.0737, -0.0613, 0.0986},
			{0.8672, 0.0718, 0.9180 /*...,*/, -0.2754, 0.2207, -0.2461},
		},
		/*...,*/
		{
			{0.6992, 1.4062, -1.6094 /*...,*/, 0.5352, -0.2256, 1.2891},
			{-2.2031, 2.0156, -2.4062 /*...,*/, 0.9219, -1.4141, 2.1094},
			{-1.3672, -0.1416, -0.1631 /*...,*/, 0.7578, -0.3613, 1.1875},
			{-0.7812, -1.7891 /*1.3594*/, 1.3125 /*...,*/, 0.7461, -0.7031, 1.5938},
			{0.2637, -0.6914, 0.5547 /*...,*/, 0.5547, -0.1299, 0.7070},
		},
		{
			{0.7344, 1.9141, 1.0312 /*...,*/, 0.5234, -0.3809, 0.4863},
			{-1.6172, 2.0156, 2.4688 /*...,*/, 0.5547, -0.4023, 0.5703},
			{-2.6094, -0.5586, 1.0547 /*...,*/, 0.6172, -0.4570, 0.6367},
			{-1.1953, -2.4688 /*-0.9141*/, -0.8554 /*...,*/, 0.6016, -0.4414, 0.6211},
			{1.6484, -2.1562, -2.3281 /*...,*/, 0.6289, -0.4688, 0.6445},
		},
		{
			{-1.3672, 0.7383, 1.3828 /*...,*/, 0.6250, -0.1670, 0.1602},
			{-0.9023, -0.5234, -0.5391 /*...,*/, 0.3789, -0.1729, -0.5195},
			{0.3535, -1.7891, -0.3477 /*...,*/, 0.3652, 0.0255, -0.1855},
			{1.2031, -0.6484, 0.2012 /*...,*/, 0.1611, -0.0103, -0.2363},
			{1.6094, 1.2344, 1.3750 /*...,*/, 0.1689, 0.1807, 0.0957},
		},
	}

	if actualXq, err = actualXq.Transpose(0, 1); err != nil { // from [5, 32, 128] -> shape=[32, 5, 128] (N_Heads, sequenceLength, HeadDim)
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedXqTranspose, expectedXqTransposeSize, actualXq, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	expectedKeysTransposeDims0_1_Size := []int{32, 5, 128}
	expectedKeysTransposeDims0_1 := [][][]float32{
		{
			{-4.5117e-01, -1.5234e-01, -1.6968e-02 /*...,*/, -2.3804e-02, -6.2109e-01, -1.2598e-01},
			{-8.0469e-01, 1.1047e-02, 4.6289e-01 /*...,*/, -1.2402e-01, 2.7539e-01, 6.0547e-01},
			{-6.5430e-02, -5.6250e-01, 2.8442e-02 /*...,*/, -2.5195e-01, 1.7578e-01, 3.5352e-01},
			{-1.8359e-01, 1.6504e-01, 2.4316e-01 /*...,*/, 2.4414e-02, -1.0352e-01, 4.7852e-02},
			{-1.7480e-01, 3.5156e-01, 4.0820e-01 /*...,*/, 2.3145e-01, -1.0498e-01, -1.6895e-01},
		},
		{
			{1.3516e+00, -6.0938e-01, 1.0781e+00 /*...,*/, -3.0469e-01, 7.5195e-02, 4.7852e-01},
			{7.4219e-01, 5.7812e-01, 7.0312e-01 /*...,*/, 3.4180e-01, 2.6953e-01, -2.2656e-01},
			{-7.2656e-01, 3.2617e-01, -4.3164e-01 /*...,*/, 2.5586e-01, -1.9824e-01, -6.9141e-01},
			{-9.3359e-01, 1.2158e-01, -4.7656e-01 /*...,*/, -4.9561e-02, 3.4570e-01, 4.3164e-01},
			{3.1055e-01, -9.4531e-01, -7.0703e-01 /*...,*/, 4.6631e-02, -3.0859e-01, -3.4180e-01},
		},
		{
			{2.0142e-03, 3.5352e-01, -2.5781e-01 /*...,*/, 4.9805e-01, -8.3203e-01, 7.6172e-01},
			{-3.3984e-01, -4.1771e-04, -1.0010e-01 /*...,*/, -5.1562e-01, 5.8984e-01, -4.6680e-01},
			{5.8594e-01, -1.7188e-01, 3.1055e-01 /*...,*/, 1.8359e+00, -1.7812e+00, 1.6953e+00},
			{-1.0986e-01, -3.6914e-01, 3.1250e-01 /*...,*/, -7.8516e-01, 7.8906e-01, -6.7969e-01},
			{-1.0254e-01, 4.7266e-01, -2.3047e-01 /*...,*/, 1.8047e+00, -1.7031e+00, 1.6484e+00},
		},
		/*...,*/
		{
			{2.4658e-02, -6.9336e-02, -4.8523e-03 /*...,*/, 9.6484e-01, -4.3164e-01, -4.0234e-01},
			{9.6680e-02, -1.3477e-01, 7.3730e-02 /*...,*/, 5.8984e-01, -1.9922e-01, -1.1133e-01},
			{1.7383e-01, -1.2422e+00, 8.7891e-01 /*...,*/, -7.1484e-01, 1.3750e+00, -1.0703e+00},
			{3.1445e-01, -1.3770e-01, 1.3965e-01 /*...,*/, 7.9590e-02, 3.0469e-01, -5.4688e-01},
			{1.5312e+00, 9.6094e-01, -4.5898e-02 /*...,*/, -1.0391e+00, 1.9141e+00, -1.3359e+00},
		},
		{
			{1.7285e-01, -7.1094e-01, -5.3906e-01 /*...,*/, 1.3672e-01, -1.8555e-01, 1.4062e-01},
			{-1.0205e-01, 3.6523e-01, 4.3555e-01 /*...,*/, -1.2256e-01, 2.3828e-01, -1.1816e-01},
			{3.4961e-01, -3.4375e-01, 7.8906e-01 /*...,*/, 1.3574e-01, -3.4570e-01, 1.3867e-01},
			{-2.2070e-01, 5.5664e-02, 6.0938e-01 /*...,*/, -2.5586e-01, 3.5156e-01, -2.5195e-01},
			{-6.9824e-02, 5.7812e-01, 3.7305e-01 /*...,*/, 9.2773e-02, -3.4375e-01, 9.1797e-02},
		},
		{
			{-4.5117e-01, 1.3477e-01, 1.2266e+00 /*...,*/, 2.1582e-01, -3.3398e-01, 2.7734e-01},
			{-3.9648e-01, -1.0156e+00, -9.0625e-01 /*...,*/, -6.4062e-01, 7.1875e-01, 3.6328e-01},
			{3.1250e-02, 1.4160e-01, -1.0107e-01 /*...,*/, 8.4375e-01, -1.0469e+00, -1.0986e-01},
			{6.7969e-01, 2.8906e-01, 2.7539e-01 /*...,*/, -5.1562e-01, 6.2891e-01, 1.5820e-01},
			{-2.0508e-01, -1.0010e-01, 3.9978e-03 /*...,*/, 9.8438e-01, -9.4922e-01, -2.4805e-01},
		},
	}

	if actualKeys, err = actualKeys.Transpose(0, 1); err != nil { // from [5, 32, 128] -> shape=[32, 5, 128] (N_Heads, sequenceLength, HeadDim)
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedKeysTransposeDims0_1, expectedKeysTransposeDims0_1_Size, actualKeys, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	expectedValuesTransposeSize := []int{32, 5, 128}
	expectedValuesTranspose := [][][]float32{
		{
			{-6.0425e-03, -6.3782e-03, 5.5847e-03 /*...,*/, 1.3809e-03, 2.0264e-02, -5.5237e-03},
			{3.8719e-04, -8.7891e-03, -3.2806e-03 /*...,*/, 5.3406e-03, 1.2131e-03, -6.1646e-03},
			{7.6904e-03, -2.2430e-03, 3.8452e-03 /*...,*/, 6.8054e-03, 1.2512e-03, 2.6245e-03},
			{-7.7057e-04, -5.3406e-03, 1.1292e-02 /*...,*/, -5.9814e-03, 5.8746e-04, -2.7084e-04},
			{3.1586e-03, 1.7166e-03, 6.1035e-04 /*...,*/, 6.3782e-03, 2.3193e-03, -9.2506e-05},
		},
		{
			{2.0599e-03, 4.0283e-03, -9.7046e-03 /*...,*/, -4.7607e-03, 6.9275e-03, -1.9043e-02},
			{8.1539e-05, -9.0790e-04, 2.3956e-03 /*...,*/, 9.7046e-03, 2.1057e-03, -3.3417e-03},
			{3.4332e-03, 1.0986e-03, 1.6708e-03 /*...,*/, -5.3101e-03, -2.9144e-03, -4.0283e-03},
			{-7.4768e-03, 1.3733e-03, -3.0212e-03 /*...,*/, 2.1820e-03, 6.9275e-03, 7.2327e-03},
			{-5.4321e-03, 1.8082e-03, -6.9275e-03 /*...,*/, 1.4420e-03, -4.1504e-03, 2.6131e-04},
		},
		{
			{-3.8605e-03, -6.4392e-03, 1.4221e-02 /*...,*/, 5.0354e-03, -1.4648e-02, 6.9885e-03},
			{7.9956e-03, -6.7139e-03, -6.6757e-04 /*...,*/, 5.0354e-03, 2.9449e-03, -3.7231e-03},
			{-7.9956e-03, 5.7373e-03, 8.3618e-03 /*...,*/, 1.8921e-03, 7.5073e-03, 6.9885e-03},
			{-1.0147e-03, -8.3618e-03, 4.1199e-03 /*...,*/, -8.4229e-03, -9.3994e-03, -6.9580e-03},
			{-2.6131e-04, 1.1444e-03, -3.2663e-05 /*...,*/, 1.2112e-04, 5.2490e-03, -1.1597e-03},
		},
		/*...,*/
		{
			{-5.9509e-04, -2.0752e-03, -1.5747e-02 /*...,*/, 2.0752e-02, 9.4604e-03, -5.1880e-03},
			{-1.0376e-02, 4.0283e-02, -6.9336e-02 /*...,*/, -9.7656e-02, -3.1494e-02, -2.0752e-02},
			{-1.4954e-03, -2.1362e-02, 3.1738e-02 /*...,*/, 1.7624e-03, -2.0752e-03, 1.6724e-02},
			{-9.4604e-03, -5.7373e-02, 2.2278e-03 /*...,*/, -5.6396e-02, -1.0071e-02, 1.3367e-02},
			{-8.8501e-03, -2.4414e-02, -3.0884e-02 /*...,*/, 2.1606e-02, -4.6387e-03, -2.1729e-02},
		},
		{
			{4.3106e-04, 1.5503e-02, -1.0254e-02 /*...,*/, -8.6060e-03, -4.5166e-02, -2.5024e-02},
			{-6.5918e-03, 2.0386e-02, -6.9885e-03 /*...,*/, -6.9580e-03, 7.9632e-05, -4.5776e-03},
			{1.0498e-02, -4.1199e-03, -1.6632e-03 /*...,*/, 6.0730e-03, -5.2795e-03, 1.2512e-03},
			{3.6926e-03, -3.4332e-03, 2.9449e-03 /*...,*/, -1.0254e-02, -1.2878e-02, 3.1738e-03},
			{1.7853e-03, 3.9062e-03, -7.5150e-04 /*...,*/, -2.8610e-04, 5.4626e-03, 1.2207e-03},
		},
		{
			{-3.9978e-03, -3.9368e-03, 4.6730e-04 /*...,*/, 1.4572e-03, -6.7139e-04, -1.4420e-03},
			{2.9144e-03, 1.0498e-02, -9.3384e-03 /*...,*/, 1.4191e-03, -9.7656e-03, 4.1809e-03},
			{6.6223e-03, -1.5503e-02, -4.6997e-03 /*...,*/, -1.2894e-03, 2.1118e-02, 2.1210e-03},
			{-4.2343e-04, 9.5749e-04, -8.3618e-03 /*...,*/, 7.9346e-04, -2.4261e-03, -4.1199e-03},
			{2.9449e-03, -1.0529e-03, -6.4697e-03 /*...,*/, -3.0136e-04, 5.5847e-03, 3.4790e-03},
		},
	}

	if actualValues, err = actualValues.Transpose(0, 1); err != nil { // from [5, 32, 128] -> shape=[32, 5, 128] (N_Heads, sequenceLength, HeadDim)
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedValuesTranspose, expectedValuesTransposeSize, actualValues, common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	expectedKeysTransposeDims1_2_Size := []int{32, 128, 5}
	expectedKeysTransposeDims1_2 := [][][]float32{
		{
			{-4.5117e-01, -8.0469e-01, -6.5430e-02, -1.8359e-01, -1.7480e-01},
			{-1.5234e-01, 1.1047e-02, -5.6250e-01, 1.6504e-01, 3.5156e-01},
			{-1.6968e-02, 4.6289e-01, 2.8442e-02, 2.4316e-01, 4.0820e-01},
			/*...,*/
			{-2.3804e-02, -1.2402e-01, -2.5195e-01, 2.4414e-02, 2.3145e-01},
			{-6.2109e-01, 2.7539e-01, 1.7578e-01, -1.0352e-01, -1.0498e-01},
			{-1.2598e-01, 6.0547e-01, 3.5352e-01, 4.7852e-02, -1.6895e-01},
		},
		{
			{1.3516e+00, 7.4219e-01, -7.2656e-01, -9.3359e-01, 3.1055e-01},
			{-6.0938e-01, 5.7812e-01, 3.2617e-01, 1.2158e-01, -9.4531e-01},
			{1.0781e+00, 7.0312e-01, -4.3164e-01, -4.7656e-01, -7.0703e-01},
			/*...,*/
			{-3.0469e-01, 3.4180e-01, 2.5586e-01, -4.9561e-02, 4.6631e-02},
			{7.5195e-02, 2.6953e-01, -1.9824e-01, 3.4570e-01, -3.0859e-01},
			{4.7852e-01, -2.2656e-01, -6.9141e-01, 4.3164e-01, -3.4180e-01},
		},
		{
			{2.0142e-03, -3.3984e-01, 5.8594e-01, -1.0986e-01, -1.0254e-01},
			{3.5352e-01, -4.1771e-04, -1.7188e-01, -3.6914e-01, 4.7266e-01},
			{-2.5781e-01, -1.0010e-01, 3.1055e-01, 3.1250e-01, -2.3047e-01},
			/*...,*/
			{4.9805e-01, -5.1562e-01, 1.8359e+00, -7.8516e-01, 1.8047e+00},
			{-8.3203e-01, 5.8984e-01, -1.7812e+00, 7.8906e-01, -1.7031e+00},
			{7.6172e-01, -4.6680e-01, 1.6953e+00, -6.7969e-01, 1.6484e+00},
		},
		/*...,*/
		{
			{2.4658e-02, 9.6680e-02, 1.7383e-01, 3.1445e-01, 1.5312e+00},
			{-6.9336e-02, -1.3477e-01, -1.2422e+00, -1.3770e-01, 9.6094e-01},
			{-4.8523e-03, 7.3730e-02, 8.7891e-01, 1.3965e-01, -4.5898e-02},
			/*...,*/
			{9.6484e-01, 5.8984e-01, -7.1484e-01, 7.9590e-02, -1.0391e+00},
			{-4.3164e-01, -1.9922e-01, 1.3750e+00, 3.0469e-01, 1.9141e+00},
			{-4.0234e-01, -1.1133e-01, -1.0703e+00, -5.4688e-01, -1.3359e+00},
		},
		{
			{1.7285e-01, -1.0205e-01, 3.4961e-01, -2.2070e-01, -6.9824e-02},
			{-7.1094e-01, 3.6523e-01, -3.4375e-01, 5.5664e-02, 5.7812e-01},
			{-5.3906e-01, 4.3555e-01, 7.8906e-01, 6.0938e-01, 3.7305e-01},
			/*...,*/
			{1.3672e-01, -1.2256e-01, 1.3574e-01, -2.5586e-01, 9.2773e-02},
			{-1.8555e-01, 2.3828e-01, -3.4570e-01, 3.5156e-01, -3.4375e-01},
			{1.4062e-01, -1.1816e-01, 1.3867e-01, -2.5195e-01, 9.1797e-02},
		},
		{
			{-4.5117e-01, -3.9648e-01, 3.1250e-02, 6.7969e-01, -2.0508e-01},
			{1.3477e-01, -1.0156e+00, 1.4160e-01, 2.8906e-01, -1.0010e-01},
			{1.2266e+00, -9.0625e-01, -1.0107e-01, 2.7539e-01, 3.9978e-03},
			/*...,*/
			{2.1582e-01, -6.4062e-01, 8.4375e-01, -5.1562e-01, 9.8438e-01},
			{-3.3398e-01, 7.1875e-01, -1.0469e+00, 6.2891e-01, -9.4922e-01},
			{2.7734e-01, 3.6328e-01, -1.0986e-01, 1.5820e-01, -2.4805e-01},
		},
	}

	if actualKeys, err = actualKeys.Transpose(1, 2); err != nil { // from [32, 5, 128] -> shape=[32, 128, 5] (N_Heads, HeadDim, sequenceLength)
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedKeysTransposeDims1_2, expectedKeysTransposeDims1_2_Size, actualKeys, 4*common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	/*
		Goal in Python manner:
		scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)
	*/

	expectedScoresSize := []int{32, 5, 5}
	expectedScores := [][][]float32{
		{
			{2.8750e+00, 2.8438e+00, 1.2109e+00, 1.1250e+00, 2.1250e+00},
			{3.4531e+00, -5.4688e-01, 7.1094e-01, 2.1406e+00, 2.7344e+00},
			{3.6250e+00, -2.1777e-01, 7.2266e-01, 2.4844e+00, 3.0000e+00},
			{2.1250e+00, -7.9688e-01, -2.1094e-01, 2.2188e+00, 2.7031e+00},
			{4.5312e+00, 9.3750e-01, 1.3672e+00, 3.1094e+00, 3.7500e+00},
		},
		{
			{5.0625e+00, 9.3750e-01, 5.2344e-01, 9.2969e-01, 3.0273e-01},
			{1.1250e+00, 2.8516e-01, 2.3438e-01, 5.1172e-01, 3.7891e-01},
			{1.0312e+00, 6.5625e-01, 3.0664e-01, 4.4727e-01, 1.1328e-01},
			{8.0078e-01, 6.3672e-01, 3.9258e-01, 6.0938e-01, 3.1445e-01},
			{8.7891e-01, 9.0625e-01, 7.3438e-01, 9.6094e-01, 3.0273e-01},
		},
		{
			{7.4219e-01, 1.4453e-01, 7.8906e-01, 5.6885e-02, 9.1016e-01},
			{1.3750e+00, 4.8633e-01, 4.3555e-01, 3.5352e-01, 7.6953e-01},
			{9.4531e-01, 7.6953e-01, -2.8906e-01, 5.8984e-01, -3.0859e-01},
			{1.0938e+00, 5.4297e-01, 1.6504e-01, 4.1992e-01, 2.6172e-01},
			{8.6328e-01, 7.8516e-01, -2.7148e-01, 7.1875e-01, -6.2109e-01},
		},
		{
			{3.6094e+00, 2.1250e+00, 2.2812e+00, 2.1250e+00, 2.1875e+00},
			{4.3125e+00, 2.8438e+00, 3.2969e+00, 2.6562e+00, 3.1406e+00},
			{4.2500e+00, 3.0469e+00, 3.3750e+00, 2.7344e+00, 3.2969e+00},
			{4.3125e+00, 3.0469e+00, 3.3438e+00, 2.8906e+00, 3.3594e+00},
			{4.2500e+00, 3.0312e+00, 3.2656e+00, 3.0469e+00, 3.4062e+00},
		},
		{
			{7.4375e+00, 3.8477e-01, 7.8516e-01, 1.6094e+00, 1.0547e+00},
			{-2.1406e+00, 5.8594e-01, 5.7422e-01, 2.5781e+00, 4.1211e-01},
			{-2.5000e+00, 8.2812e-01, 7.3047e-01, 2.5000e+00, 3.3008e-01},
			{-2.0781e+00, 5.8594e-01, 6.8359e-01, 2.4531e+00, 4.0039e-01},
			{-2.2812e+00, 7.6953e-01, 7.5000e-01, 2.7344e+00, 5.7812e-01},
		},
		{
			{2.2031e+00, 7.6172e-01, 1.2969e+00, 6.3672e-01, 1.4453e+00},
			{-1.4375e+00, 1.0889e-01, 4.3555e-01, 5.2490e-02, 5.8203e-01},
			{-2.9883e-01, 5.6641e-01, 6.5625e-01, 4.9805e-01, 8.0469e-01},
			{-9.4531e-01, -5.0781e-02, 9.8633e-02, -6.1035e-04, 2.9297e-01},
			{2.5000e-01, 9.1797e-01, 1.0391e+00, 8.3984e-01, 1.0234e+00},
		},
		{
			{2.9219e+00, 3.7344e+00, 2.0156e+00, 2.4219e+00, 1.5391e+00},
			{1.3828e+00, 3.9375e+00, 2.0625e+00, 2.8906e+00, 1.1016e+00},
			{9.7266e-01, 1.7031e+00, 1.7812e+00, 1.6016e+00, 1.2969e+00},
			{1.0469e+00, 3.9258e-01, 6.1719e-01, 2.1719e+00, 6.5234e-01},
			{1.1797e+00, 1.0156e+00, 1.3281e+00, 1.4688e+00, 1.2500e+00},
		},
		{
			{9.1016e-01, 2.2070e-01, 6.1328e-01, -5.7812e-01, 7.5781e-01},
			{1.3672e+00, -9.6436e-03, 1.2207e-01, -1.2734e+00, 2.9492e-01},
			{1.3906e+00, 2.7930e-01, 2.4707e-01, -1.4141e+00, 3.0823e-03},
			{1.4141e+00, 5.7812e-01, 6.5234e-01, -1.4219e+00, -1.4453e-01},
			{1.5156e+00, 6.6016e-01, 1.0469e+00, -1.2109e+00, 4.0894e-03},
		},
		{
			{2.0410e-01, 1.2500e-01, 3.5645e-02, -2.7539e-01, -8.4961e-02},
			{-3.2227e-01, 2.3242e-01, 1.1475e-01, 5.9766e-01, 8.7109e-01},
			{6.4844e-01, 1.4453e+00, 9.4922e-01, 1.5469e+00, 1.8047e+00},
			{-6.0547e-01, -2.1680e-01, -2.8687e-02, 7.3047e-01, 8.3984e-01},
			{2.2969e+00, 3.2031e+00, 2.1562e+00, 2.7812e+00, 2.7656e+00},
		},
		{
			{1.8672e+00, 6.2891e-01, 2.0020e-01, -4.3945e-01, 9.3359e-01},
			{1.4688e+00, 1.3516e+00, 4.3164e-01, -1.2578e+00, 1.3672e+00},
			{1.1172e+00, 1.3125e+00, 6.8750e-01, -1.0234e+00, 1.0938e+00},
			{1.1875e+00, 1.2188e+00, 8.4375e-01, -1.2891e+00, 1.4688e+00},
			{1.1172e+00, 7.8906e-01, 1.1484e+00, -9.8828e-01, 1.8594e+00},
		},
		{
			{4.1250e+00, 2.5000e+00, 1.9297e+00, 1.8984e+00, 2.0312e+00},
			{1.4062e+00, 1.1797e+00, 5.9375e-01, 1.1953e+00, 1.0547e+00},
			{1.9141e+00, 1.8672e+00, 6.4844e-01, 1.8594e+00, 1.0078e+00},
			{6.7578e-01, 8.3594e-01, 4.5898e-01, 1.2344e+00, 7.7734e-01},
			{2.0156e+00, 1.8984e+00, 1.0938e+00, 2.2344e+00, 1.0078e+00},
		},
		{
			{-9.0625e-01, 4.3555e-01, 8.9453e-01, -2.9907e-02, 1.8984e+00},
			{-2.0938e+00, -3.3594e-01, 3.0859e-01, -5.2344e-01, 1.2344e+00},
			{-1.9766e+00, -2.9883e-01, 4.3945e-01, -6.5625e-01, 1.2188e+00},
			{-1.7266e+00, -1.7578e-01, 5.7812e-01, -6.6016e-01, 1.4688e+00},
			{-1.5703e+00, -2.6172e-01, 6.2500e-01, -6.5234e-01, 1.8047e+00},
		},
		{
			{3.2656e+00, 1.1953e+00, 3.7109e-01, 1.4453e+00, 9.7266e-01},
			{4.4062e+00, 4.2500e+00, 3.1562e+00, 3.1875e+00, 2.9219e+00},
			{4.3750e+00, 3.2188e+00, 4.0000e+00, 2.9375e+00, 3.7500e+00},
			{3.1875e+00, 3.2031e+00, 2.7500e+00, 3.6719e+00, 2.9688e+00},
			{3.8281e+00, 2.8125e+00, 3.5156e+00, 2.7969e+00, 3.4531e+00},
		},
		{
			{1.3438e+00, 3.7305e-01, -3.4375e-01, 2.8320e-01, -2.0605e-01},
			{3.3203e-01, 4.5508e-01, -9.7656e-03, -2.3730e-01, -5.7617e-02},
			{4.5312e-01, 6.6016e-01, -5.8350e-02, -1.7773e-01, -2.5000e-01},
			{5.7031e-01, 7.5000e-01, 9.7168e-02, -1.6406e-01, -3.0469e-01},
			{6.8359e-01, 6.9141e-01, 1.9238e-01, 4.1992e-02, -2.9492e-01},
		},
		{
			{1.4609e+00, 9.4531e-01, 1.0625e+00, 6.8750e-01, 1.2734e+00},
			{5.8984e-01, 3.5938e-01, -1.1865e-01, 7.4219e-02, 2.9883e-01},
			{7.3438e-01, 8.6719e-01, 3.4180e-01, 3.6133e-01, 3.6133e-01},
			{6.7188e-01, 9.3359e-01, 4.1797e-01, 3.4570e-01, 2.5977e-01},
			{8.9453e-01, 1.0156e+00, 9.8828e-01, 6.8750e-01, 4.3359e-01},
		},
		{
			{8.8281e-01, 4.2188e-01, 3.7109e-01, 4.1406e-01, 3.7305e-01},
			{1.6094e+00, 1.3516e+00, 5.9375e-01, 1.1172e+00, 4.5898e-01},
			{1.5469e+00, 1.3516e+00, 6.5625e-01, 1.1797e+00, 4.1406e-01},
			{1.4844e+00, 1.2656e+00, 7.8516e-01, 1.2266e+00, 5.2734e-01},
			{1.3516e+00, 1.1250e+00, 7.2266e-01, 1.1953e+00, 5.4297e-01},
		},
		{
			{1.1406e+00, 1.2188e+00, 1.8984e+00, 1.2812e+00, 1.7266e+00},
			{1.5547e+00, 1.5234e+00, 3.6523e-01, 5.9766e-01, 2.1387e-01},
			{8.1641e-01, 2.2500e+00, 1.2344e+00, 1.5703e+00, 9.2969e-01},
			{1.6250e+00, 2.2812e+00, 8.9062e-01, 1.2812e+00, 5.0391e-01},
			{5.3516e-01, 2.2812e+00, 1.4922e+00, 2.2344e+00, 8.6328e-01},
		},
		{
			{2.3906e+00, 3.7188e+00, 5.3125e-01, 2.3594e+00, 8.2812e-01},
			{6.7188e-01, 1.0547e+00, 1.2188e+00, 1.0312e+00, 1.4375e+00},
			{2.8516e-01, 8.7891e-01, 8.6328e-01, 8.2422e-01, 8.2812e-01},
			{4.5508e-01, 8.6328e-01, 1.1562e+00, 1.0859e+00, 9.7656e-01},
			{1.5137e-01, 6.7578e-01, 9.2969e-01, 9.7656e-01, 8.1641e-01},
		},
		{
			{2.5625e+00, 3.6875e+00, 3.2500e+00, 3.2656e+00, 4.0312e+00},
			{2.1094e+00, 3.2188e+00, 3.1562e+00, 2.7969e+00, 3.3438e+00},
			{3.1094e+00, 3.6875e+00, 2.8438e+00, 3.2031e+00, 3.1094e+00},
			{9.7266e-01, 1.5469e+00, 2.2969e+00, 1.5156e+00, 1.8203e+00},
			{3.1406e+00, 3.3438e+00, 3.0312e+00, 3.6875e+00, 3.0000e+00},
		},
		{
			{3.2500e+00, 3.2422e-01, 3.3125e+00, 1.4609e+00, 3.2500e+00},
			{4.5312e+00, 3.6719e-01, 4.7188e+00, 1.8906e+00, 4.5625e+00},
			{4.7188e+00, 5.1172e-01, 4.8750e+00, 2.0156e+00, 4.7812e+00},
			{4.9375e+00, 5.8984e-01, 4.9375e+00, 2.2500e+00, 4.9375e+00},
			{4.9375e+00, 7.7734e-01, 4.9375e+00, 2.3906e+00, 5.0312e+00},
		},
		{
			{3.7969e+00, 2.1094e+00, 2.2031e+00, 1.3672e+00, 2.1094e+00},
			{1.3672e+00, 1.2266e+00, 1.1250e+00, 9.5703e-01, 1.2891e+00},
			{3.7305e-01, 8.7109e-01, 6.4844e-01, 6.9922e-01, 1.0469e+00},
			{1.8047e+00, 1.4062e+00, 1.4844e+00, 1.1250e+00, 1.6562e+00},
			{-1.5625e-01, 3.7109e-01, 4.4727e-01, 5.3125e-01, 8.9453e-01},
		},
		{
			{-2.1875e+00, 7.3438e-01, 3.8086e-01, 3.7109e-01, 4.2578e-01},
			{5.1953e-01, 8.5547e-01, -3.6719e-01, 1.4453e-01, -2.2266e-01},
			{7.5781e-01, 7.7344e-01, -4.2188e-01, 1.0205e-01, -5.2344e-01},
			{9.8828e-01, 8.7109e-01, -2.6172e-01, 2.0020e-01, -6.4453e-01},
			{9.2188e-01, 7.0312e-01, 4.5654e-02, 3.7500e-01, -6.0156e-01},
		},
		{
			{2.9375e+00, 1.8438e+00, 2.1562e+00, 1.5938e+00, 1.3906e+00},
			{3.0664e-01, 1.6094e+00, 2.1719e+00, 3.0312e+00, 1.9688e+00},
			{1.4343e-02, -3.2422e-01, 2.0625e+00, 2.4688e+00, 3.0781e+00},
			{1.0547e-01, -1.6094e+00, 4.8047e-01, 1.8594e+00, 2.3281e+00},
			{4.6680e-01, -2.4062e+00, 2.1387e-01, 4.5312e-01, 2.4844e+00},
		},
		{
			{2.9219e+00, 1.6797e+00, 1.8652e-01, 1.4609e+00, -5.4297e-01},
			{1.0469e+00, 1.5469e+00, 3.3203e-01, 1.9453e+00, -3.8477e-01},
			{1.2578e+00, 6.8359e-01, 2.2344e+00, 1.9141e+00, 2.3750e+00},
			{1.3672e+00, 7.8516e-01, -2.6172e-01, 1.6250e+00, 2.2656e-01},
			{1.4453e+00, 2.0898e-01, -1.3086e-01, 1.1816e-01, 2.2812e+00},
		},
		{
			{2.2656e+00, 1.4375e+00, -2.7148e-01, 1.7812e+00, 1.2695e-01},
			{1.1797e+00, 3.2812e-01, -1.7656e+00, 3.9258e-01, -1.6562e+00},
			{1.3828e+00, 7.4219e-01, -1.5938e+00, 1.6602e-01, -1.8359e+00},
			{1.2891e+00, 1.0859e+00, -1.3281e+00, 2.5781e-01, -1.8438e+00},
			{9.8438e-01, 1.1953e+00, -1.0625e+00, 7.6953e-01, -1.6328e+00},
		},
		{
			{6.6406e-01, 1.0352e-01, -2.9492e-01, 5.4932e-03, -2.0605e-01},
			{1.6719e+00, 1.7266e+00, 1.1016e+00, 1.2188e+00, 1.0625e+00},
			{1.5938e+00, 1.7578e+00, 1.1562e+00, 1.2656e+00, 1.0156e+00},
			{1.5938e+00, 1.7266e+00, 1.2188e+00, 1.3359e+00, 1.0703e+00},
			{1.4844e+00, 1.5703e+00, 1.0781e+00, 1.3125e+00, 1.0703e+00},
		},
		{
			{-1.1797e+00, 8.1641e-01, 7.5684e-02, 3.0518e-02, -1.7480e-01},
			{-1.2969e+00, 8.3984e-01, 9.0234e-01, 7.1875e-01, 1.1562e+00},
			{-3.0078e-01, 1.7266e+00, 1.8203e+00, 1.8594e+00, 2.1250e+00},
			{-3.5547e-01, 1.4609e+00, 1.7344e+00, 1.7266e+00, 2.2500e+00},
			{2.9102e-01, 1.6797e+00, 2.0625e+00, 2.5469e+00, 3.1406e+00},
		},
		{
			{5.7031e-01, 4.4727e-01, 1.4688e+00, 3.5156e-01, 9.7656e-01},
			{1.3125e+00, 7.8516e-01, 1.7344e+00, 2.2363e-01, 1.6094e+00},
			{1.7031e+00, 8.7109e-01, 1.5000e+00, -1.5430e-01, 1.7266e+00},
			{2.2188e+00, 1.0859e+00, 9.9609e-01, -1.5137e-01, 1.4688e+00},
			{2.1562e+00, 1.1562e+00, 7.0312e-01, 7.8613e-02, 1.2578e+00},
		},
		{
			{4.8750e+00, 1.2734e+00, 1.2656e+00, 1.3906e+00, 1.5547e+00},
			{1.3047e+00, 9.8633e-02, 1.1016e+00, 1.1328e+00, 1.5391e+00},
			{2.3906e+00, 8.5156e-01, 1.5234e+00, 1.6875e+00, 1.9688e+00},
			{1.6719e+00, 7.6172e-01, 1.5781e+00, 1.5781e+00, 1.8984e+00},
			{2.7656e+00, 1.1562e+00, 1.7891e+00, 1.9688e+00, 2.1875e+00},
		},
		{
			{2.0938e+00, 7.8906e-01, -1.5547e+00, -3.4570e-01, -1.9531e+00},
			{5.7500e+00, 1.6484e+00, -8.7109e-01, 2.8516e-01, -2.7656e+00},
			{5.9375e+00, 2.2656e+00, 1.3828e+00, 1.4688e+00, -3.9551e-02},
			{5.4688e+00, 2.1562e+00, 1.5234e+00, 1.3047e+00, -9.2969e-01},
			{5.8438e+00, 2.1562e+00, 2.0938e+00, 1.5547e+00, 1.8672e+00},
		},
		{
			{-2.2500e+00, -4.0625e-01, 9.8438e-01, -1.4453e+00, 1.4941e-01},
			{-1.9219e+00, -6.4844e-01, 7.5000e-01, -2.3125e+00, -3.8477e-01},
			{-1.6328e+00, -4.8242e-01, 1.0625e+00, -2.5000e+00, -2.2949e-01},
			{-9.7656e-01, -6.0938e-01, 9.2969e-01, -2.6250e+00, -3.3008e-01},
			{-5.7812e-01, -5.9375e-01, 9.7266e-01, -2.3906e+00, -2.3438e-01},
		},
		{
			{1.0812e+01, 2.4375e+00, 1.4844e+00, 1.7031e+00, 1.9453e+00},
			{1.3906e+00, 1.0781e+00, 4.2773e-01, 6.6406e-01, 7.8906e-01},
			{1.0469e+00, 1.8594e+00, 4.0234e-01, 1.4688e+00, 7.3438e-01},
			{5.1953e-01, 6.7188e-01, 5.5859e-01, 9.6094e-01, 7.7734e-01},
			{6.6016e-01, 5.1562e-01, 4.8828e-01, 1.7344e+00, 8.0469e-01},
		},
	}

	xqMatMulKeys, err := ml.MatMul(actualXq, actualKeys) // matmul([32,5,128], [32,128,5]) -> shape=[32,5,5] (N_Heads, sequenceLength, sequenceLength)
	if err != nil {
		t.Fatal(err)
	}
	actualScores, err := ml.DivToScalar(xqMatMulKeys, dtype.BFloat16fromFloat32(float32(math.Sqrt(float64(attention.HeadDim))))) // shape=[32,5,5]
	if err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedScores, expectedScoresSize, actualScores, 30*common.THRESHOLD_BF16, false); err != nil {
		t.Fatal(err)
	}
	negInf := float32(math.Inf(-1))

	if mask != nil {
		expectedScoresPlusMaskSize := []int{32, 5, 5}
		expectedScoresPlusMask := [][][]float32{
			{
				{2.8750e+00, negInf, negInf, negInf, negInf},
				{3.4531e+00, -5.4688e-01, negInf, negInf, negInf},
				{3.6250e+00, -2.1777e-01, 7.2266e-01, negInf, negInf},
				{2.1250e+00, -7.9688e-01, -2.1094e-01, 2.2188e+00, negInf},
				{4.5312e+00, 9.3750e-01, 1.3672e+00, 3.1094e+00, 3.7500e+00},
			},

			{
				{5.0625e+00, negInf, negInf, negInf, negInf},
				{1.1250e+00, 2.8516e-01, negInf, negInf, negInf},
				{1.0312e+00, 6.5625e-01, 3.0664e-01, negInf, negInf},
				{8.0078e-01, 6.3672e-01, 3.9258e-01, 6.0938e-01, negInf},
				{8.7891e-01, 9.0625e-01, 7.3438e-01, 9.6094e-01, 3.0273e-01},
			},

			{
				{7.4219e-01, negInf, negInf, negInf, negInf},
				{1.3750e+00, 4.8633e-01, negInf, negInf, negInf},
				{9.4531e-01, 7.6953e-01, -2.8906e-01, negInf, negInf},
				{1.0938e+00, 5.4297e-01, 1.6504e-01, 4.1992e-01, negInf},
				{8.6328e-01, 7.8516e-01, -2.7148e-01, 7.1875e-01, -6.2109e-01},
			},

			{
				{3.6094e+00, negInf, negInf, negInf, negInf},
				{4.3125e+00, 2.8438e+00, negInf, negInf, negInf},
				{4.2500e+00, 3.0469e+00, 3.3750e+00, negInf, negInf},
				{4.3125e+00, 3.0469e+00, 3.3438e+00, 2.8906e+00, negInf},
				{4.2500e+00, 3.0312e+00, 3.2656e+00, 3.0469e+00, 3.4062e+00},
			},

			{
				{7.4375e+00, negInf, negInf, negInf, negInf},
				{-2.1406e+00, 5.8594e-01, negInf, negInf, negInf},
				{-2.5000e+00, 8.2812e-01, 7.3047e-01, negInf, negInf},
				{-2.0781e+00, 5.8594e-01, 6.8359e-01, 2.4531e+00, negInf},
				{-2.2812e+00, 7.6953e-01, 7.5000e-01, 2.7344e+00, 5.7812e-01},
			},

			{
				{2.2031e+00, negInf, negInf, negInf, negInf},
				{-1.4375e+00, 1.0889e-01, negInf, negInf, negInf},
				{-2.9883e-01, 5.6641e-01, 6.5625e-01, negInf, negInf},
				{-9.4531e-01, -5.0781e-02, 9.8633e-02, -6.1035e-04, negInf},
				{2.5000e-01, 9.1797e-01, 1.0391e+00, 8.3984e-01, 1.0234e+00},
			},

			{
				{2.9219e+00, negInf, negInf, negInf, negInf},
				{1.3828e+00, 3.9375e+00, negInf, negInf, negInf},
				{9.7266e-01, 1.7031e+00, 1.7812e+00, negInf, negInf},
				{1.0469e+00, 3.9258e-01, 6.1719e-01, 2.1719e+00, negInf},
				{1.1797e+00, 1.0156e+00, 1.3281e+00, 1.4688e+00, 1.2500e+00},
			},

			{
				{9.1016e-01, negInf, negInf, negInf, negInf},
				{1.3672e+00, -9.6436e-03, negInf, negInf, negInf},
				{1.3906e+00, 2.7930e-01, 2.4707e-01, negInf, negInf},
				{1.4141e+00, 5.7812e-01, 6.5234e-01, -1.4219e+00, negInf},
				{1.5156e+00, 6.6016e-01, 1.0469e+00, -1.2109e+00, 4.0894e-03},
			},

			{
				{2.0410e-01, negInf, negInf, negInf, negInf},
				{-3.2227e-01, 2.3242e-01, negInf, negInf, negInf},
				{6.4844e-01, 1.4453e+00, 9.4922e-01, negInf, negInf},
				{-6.0547e-01, -2.1680e-01, -2.8687e-02, 7.3047e-01, negInf},
				{2.2969e+00, 3.2031e+00, 2.1562e+00, 2.7812e+00, 2.7656e+00},
			},

			{
				{1.8672e+00, negInf, negInf, negInf, negInf},
				{1.4688e+00, 1.3516e+00, negInf, negInf, negInf},
				{1.1172e+00, 1.3125e+00, 6.8750e-01, negInf, negInf},
				{1.1875e+00, 1.2188e+00, 8.4375e-01, -1.2891e+00, negInf},
				{1.1172e+00, 7.8906e-01, 1.1484e+00, -9.8828e-01, 1.8594e+00},
			},

			{
				{4.1250e+00, negInf, negInf, negInf, negInf},
				{1.4062e+00, 1.1797e+00, negInf, negInf, negInf},
				{1.9141e+00, 1.8672e+00, 6.4844e-01, negInf, negInf},
				{6.7578e-01, 8.3594e-01, 4.5898e-01, 1.2344e+00, negInf},
				{2.0156e+00, 1.8984e+00, 1.0938e+00, 2.2344e+00, 1.0078e+00},
			},

			{
				{-9.0625e-01, negInf, negInf, negInf, negInf},
				{-2.0938e+00, -3.3594e-01, negInf, negInf, negInf},
				{-1.9766e+00, -2.9883e-01, 4.3945e-01, negInf, negInf},
				{-1.7266e+00, -1.7578e-01, 5.7812e-01, -6.6016e-01, negInf},
				{-1.5703e+00, -2.6172e-01, 6.2500e-01, -6.5234e-01, 1.8047e+00},
			},

			{
				{3.2656e+00, negInf, negInf, negInf, negInf},
				{4.4062e+00, 4.2500e+00, negInf, negInf, negInf},
				{4.3750e+00, 3.2188e+00, 4.0000e+00, negInf, negInf},
				{3.1875e+00, 3.2031e+00, 2.7500e+00, 3.6719e+00, negInf},
				{3.8281e+00, 2.8125e+00, 3.5156e+00, 2.7969e+00, 3.4531e+00},
			},

			{
				{1.3438e+00, negInf, negInf, negInf, negInf},
				{3.3203e-01, 4.5508e-01, negInf, negInf, negInf},
				{4.5312e-01, 6.6016e-01, -5.8350e-02, negInf, negInf},
				{5.7031e-01, 7.5000e-01, 9.7168e-02, -1.6406e-01, negInf},
				{6.8359e-01, 6.9141e-01, 1.9238e-01, 4.1992e-02, -2.9492e-01},
			},

			{
				{1.4609e+00, negInf, negInf, negInf, negInf},
				{5.8984e-01, 3.5938e-01, negInf, negInf, negInf},
				{7.3438e-01, 8.6719e-01, 3.4180e-01, negInf, negInf},
				{6.7188e-01, 9.3359e-01, 4.1797e-01, 3.4570e-01, negInf},
				{8.9453e-01, 1.0156e+00, 9.8828e-01, 6.8750e-01, 4.3359e-01},
			},

			{
				{8.8281e-01, negInf, negInf, negInf, negInf},
				{1.6094e+00, 1.3516e+00, negInf, negInf, negInf},
				{1.5469e+00, 1.3516e+00, 6.5625e-01, negInf, negInf},
				{1.4844e+00, 1.2656e+00, 7.8516e-01, 1.2266e+00, negInf},
				{1.3516e+00, 1.1250e+00, 7.2266e-01, 1.1953e+00, 5.4297e-01},
			},

			{
				{1.1406e+00, negInf, negInf, negInf, negInf},
				{1.5547e+00, 1.5234e+00, negInf, negInf, negInf},
				{8.1641e-01, 2.2500e+00, 1.2344e+00, negInf, negInf},
				{1.6250e+00, 2.2812e+00, 8.9062e-01, 1.2812e+00, negInf},
				{5.3516e-01, 2.2812e+00, 1.4922e+00, 2.2344e+00, 8.6328e-01},
			},

			{
				{2.3906e+00, negInf, negInf, negInf, negInf},
				{6.7188e-01, 1.0547e+00, negInf, negInf, negInf},
				{2.8516e-01, 8.7891e-01, 8.6328e-01, negInf, negInf},
				{4.5508e-01, 8.6328e-01, 1.1562e+00, 1.0859e+00, negInf},
				{1.5137e-01, 6.7578e-01, 9.2969e-01, 9.7656e-01, 8.1641e-01},
			},

			{
				{2.5625e+00, negInf, negInf, negInf, negInf},
				{2.1094e+00, 3.2188e+00, negInf, negInf, negInf},
				{3.1094e+00, 3.6875e+00, 2.8438e+00, negInf, negInf},
				{9.7266e-01, 1.5469e+00, 2.2969e+00, 1.5156e+00, negInf},
				{3.1406e+00, 3.3438e+00, 3.0312e+00, 3.6875e+00, 3.0000e+00},
			},

			{
				{3.2500e+00, negInf, negInf, negInf, negInf},
				{4.5312e+00, 3.6719e-01, negInf, negInf, negInf},
				{4.7188e+00, 5.1172e-01, 4.8750e+00, negInf, negInf},
				{4.9375e+00, 5.8984e-01, 4.9375e+00, 2.2500e+00, negInf},
				{4.9375e+00, 7.7734e-01, 4.9375e+00, 2.3906e+00, 5.0312e+00},
			},

			{
				{3.7969e+00, negInf, negInf, negInf, negInf},
				{1.3672e+00, 1.2266e+00, negInf, negInf, negInf},
				{3.7305e-01, 8.7109e-01, 6.4844e-01, negInf, negInf},
				{1.8047e+00, 1.4062e+00, 1.4844e+00, 1.1250e+00, negInf},
				{-1.5625e-01, 3.7109e-01, 4.4727e-01, 5.3125e-01, 8.9453e-01},
			},

			{
				{-2.1875e+00, negInf, negInf, negInf, negInf},
				{5.1953e-01, 8.5547e-01, negInf, negInf, negInf},
				{7.5781e-01, 7.7344e-01, -4.2188e-01, negInf, negInf},
				{9.8828e-01, 8.7109e-01, -2.6172e-01, 2.0020e-01, negInf},
				{9.2188e-01, 7.0312e-01, 4.5654e-02, 3.7500e-01, -6.0156e-01},
			},

			{
				{2.9375e+00, negInf, negInf, negInf, negInf},
				{3.0664e-01, 1.6094e+00, negInf, negInf, negInf},
				{1.4343e-02, -3.2422e-01, 2.0625e+00, negInf, negInf},
				{1.0547e-01, -1.6094e+00, 4.8047e-01, 1.8594e+00, negInf},
				{4.6680e-01, -2.4062e+00, 2.1387e-01, 4.5312e-01, 2.4844e+00},
			},

			{
				{2.9219e+00, negInf, negInf, negInf, negInf},
				{1.0469e+00, 1.5469e+00, negInf, negInf, negInf},
				{1.2578e+00, 6.8359e-01, 2.2344e+00, negInf, negInf},
				{1.3672e+00, 7.8516e-01, -2.6172e-01, 1.6250e+00, negInf},
				{1.4453e+00, 2.0898e-01, -1.3086e-01, 1.1816e-01, 2.2812e+00},
			},

			{
				{2.2656e+00, negInf, negInf, negInf, negInf},
				{1.1797e+00, 3.2812e-01, negInf, negInf, negInf},
				{1.3828e+00, 7.4219e-01, -1.5938e+00, negInf, negInf},
				{1.2891e+00, 1.0859e+00, -1.3281e+00, 2.5781e-01, negInf},
				{9.8438e-01, 1.1953e+00, -1.0625e+00, 7.6953e-01, -1.6328e+00},
			},

			{
				{6.6406e-01, negInf, negInf, negInf, negInf},
				{1.6719e+00, 1.7266e+00, negInf, negInf, negInf},
				{1.5938e+00, 1.7578e+00, 1.1562e+00, negInf, negInf},
				{1.5938e+00, 1.7266e+00, 1.2188e+00, 1.3359e+00, negInf},
				{1.4844e+00, 1.5703e+00, 1.0781e+00, 1.3125e+00, 1.0703e+00},
			},

			{
				{-1.1797e+00, negInf, negInf, negInf, negInf},
				{-1.2969e+00, 8.3984e-01, negInf, negInf, negInf},
				{-3.0078e-01, 1.7266e+00, 1.8203e+00, negInf, negInf},
				{-3.5547e-01, 1.4609e+00, 1.7344e+00, 1.7266e+00, negInf},
				{2.9102e-01, 1.6797e+00, 2.0625e+00, 2.5469e+00, 3.1406e+00},
			},

			{
				{5.7031e-01, negInf, negInf, negInf, negInf},
				{1.3125e+00, 7.8516e-01, negInf, negInf, negInf},
				{1.7031e+00, 8.7109e-01, 1.5000e+00, negInf, negInf},
				{2.2188e+00, 1.0859e+00, 9.9609e-01, -1.5137e-01, negInf},
				{2.1562e+00, 1.1562e+00, 7.0312e-01, 7.8613e-02, 1.2578e+00},
			},

			{
				{4.8750e+00, negInf, negInf, negInf, negInf},
				{1.3047e+00, 9.8633e-02, negInf, negInf, negInf},
				{2.3906e+00, 8.5156e-01, 1.5234e+00, negInf, negInf},
				{1.6719e+00, 7.6172e-01, 1.5781e+00, 1.5781e+00, negInf},
				{2.7656e+00, 1.1562e+00, 1.7891e+00, 1.9688e+00, 2.1875e+00},
			},

			{
				{2.0938e+00, negInf, negInf, negInf, negInf},
				{5.7500e+00, 1.6484e+00, negInf, negInf, negInf},
				{5.9375e+00, 2.2656e+00, 1.3828e+00, negInf, negInf},
				{5.4688e+00, 2.1562e+00, 1.5234e+00, 1.3047e+00, negInf},
				{5.8438e+00, 2.1562e+00, 2.0938e+00, 1.5547e+00, 1.8672e+00},
			},

			{
				{-2.2500e+00, negInf, negInf, negInf, negInf},
				{-1.9219e+00, -6.4844e-01, negInf, negInf, negInf},
				{-1.6328e+00, -4.8242e-01, 1.0625e+00, negInf, negInf},
				{-9.7656e-01, -6.0938e-01, 9.2969e-01, -2.6250e+00, negInf},
				{-5.7812e-01, -5.9375e-01, 9.7266e-01, -2.3906e+00, -2.3438e-01},
			},

			{
				{1.0812e+01, negInf, negInf, negInf, negInf},
				{1.3906e+00, 1.0781e+00, negInf, negInf, negInf},
				{1.0469e+00, 1.8594e+00, 4.0234e-01, negInf, negInf},
				{5.1953e-01, 6.7188e-01, 5.5859e-01, 9.6094e-01, negInf},
				{6.6016e-01, 5.1562e-01, 4.8828e-01, 1.7344e+00, 8.0469e-01},
			},
		}
		if actualScores, err = ml.Add(actualScores, mask); err != nil { // shape=[32,5,5]
			t.Fatal(err)
		}
		if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedScoresPlusMask, expectedScoresPlusMaskSize, actualScores, 30*common.THRESHOLD_BF16, false); err != nil {
			t.Fatal(err)
		}
	}

	/*
		Goal in Python manner:
		scores = F.softmax(scores.float(), dim=-1).type_as(xq)
	*/

	expectedScoresSoftmaxSize := []int{32, 5, 5}
	expectedScoresSoftmax := [][][]float32{
		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.9805, 0.0179, 0.0000, 0.0000, 0.0000},
			{0.9297, 0.0199, 0.0510, 0.0000, 0.0000},
			{0.4453, 0.0239, 0.0430, 0.4883, 0.0000},
			{0.5664, 0.0156, 0.0239, 0.1367, 0.2598},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.6992, 0.3008, 0.0000, 0.0000, 0.0000},
			{0.4609, 0.3164, 0.2227, 0.0000, 0.0000},
			{0.2988, 0.2539, 0.1992, 0.2471, 0.0000},
			{0.2207, 0.2266, 0.1904, 0.2393, 0.1240},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.7070, 0.2910, 0.0000, 0.0000, 0.0000},
			{0.4688, 0.3945, 0.1367, 0.0000, 0.0000},
			{0.4023, 0.2324, 0.1592, 0.2051, 0.0000},
			{0.2988, 0.2773, 0.0962, 0.2598, 0.0679},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.8125, 0.1875, 0.0000, 0.0000, 0.0000},
			{0.5820, 0.1748, 0.2432, 0.0000, 0.0000},
			{0.5273, 0.1484, 0.1992, 0.1270, 0.0000},
			{0.4160, 0.1230, 0.1553, 0.1250, 0.1797},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.0615, 0.9375, 0.0000, 0.0000, 0.0000},
			{0.0184, 0.5156, 0.4668, 0.0000, 0.0000},
			{0.0081, 0.1157, 0.1279, 0.7500, 0.0000},
			{0.0047, 0.1001, 0.0981, 0.7148, 0.0825},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.1758, 0.8242, 0.0000, 0.0000, 0.0000},
			{0.1670, 0.3984, 0.4355, 0.0000, 0.0000},
			{0.1128, 0.2754, 0.3203, 0.2910, 0.0000},
			{0.1094, 0.2139, 0.2412, 0.1973, 0.2373},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.0723, 0.9297, 0.0000, 0.0000, 0.0000},
			{0.1875, 0.3906, 0.4219, 0.0000, 0.0000},
			{0.1904, 0.0991, 0.1240, 0.5859, 0.0000},
			{0.1846, 0.1562, 0.2139, 0.2461, 0.1982},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.7969, 0.2012, 0.0000, 0.0000, 0.0000},
			{0.6055, 0.2002, 0.1934, 0.0000, 0.0000},
			{0.5117, 0.2217, 0.2383, 0.0299, 0.0000},
			{0.4277, 0.1816, 0.2676, 0.0280, 0.0942},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.3652, 0.6367, 0.0000, 0.0000, 0.0000},
			{0.2188, 0.4863, 0.2949, 0.0000, 0.0000},
			{0.1240, 0.1826, 0.2207, 0.4727, 0.0000},
			{0.1318, 0.3281, 0.1147, 0.2148, 0.2109},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5273, 0.4707, 0.0000, 0.0000, 0.0000},
			{0.3496, 0.4238, 0.2266, 0.0000, 0.0000},
			{0.3535, 0.3652, 0.2520, 0.0298, 0.0000},
			{0.2012, 0.1445, 0.2070, 0.0245, 0.4219},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5547, 0.4434, 0.0000, 0.0000, 0.0000},
			{0.4473, 0.4258, 0.1260, 0.0000, 0.0000},
			{0.2119, 0.2480, 0.1699, 0.3691, 0.0000},
			{0.2559, 0.2285, 0.1021, 0.3203, 0.0938},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.1475, 0.8516, 0.0000, 0.0000, 0.0000},
			{0.0569, 0.3047, 0.6367, 0.0000, 0.0000},
			{0.0537, 0.2539, 0.5391, 0.1562, 0.0000},
			{0.0220, 0.0815, 0.1982, 0.0552, 0.6445},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5391, 0.4609, 0.0000, 0.0000, 0.0000},
			{0.5000, 0.1572, 0.3438, 0.0000, 0.0000},
			{0.2334, 0.2373, 0.1504, 0.3789, 0.0000},
			{0.3184, 0.1152, 0.2334, 0.1138, 0.2188},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.4688, 0.5312, 0.0000, 0.0000, 0.0000},
			{0.3535, 0.4355, 0.2119, 0.0000, 0.0000},
			{0.3027, 0.3633, 0.1885, 0.1455, 0.0000},
			{0.2832, 0.2871, 0.1738, 0.1494, 0.1069},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5586, 0.4434, 0.0000, 0.0000, 0.0000},
			{0.3555, 0.4062, 0.2393, 0.0000, 0.0000},
			{0.2637, 0.3418, 0.2041, 0.1904, 0.0000},
			{0.2139, 0.2412, 0.2354, 0.1738, 0.1348},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5625, 0.4355, 0.0000, 0.0000, 0.0000},
			{0.4473, 0.3691, 0.1836, 0.0000, 0.0000},
			{0.3262, 0.2617, 0.1621, 0.2520, 0.0000},
			{0.2754, 0.2197, 0.1465, 0.2354, 0.1226},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5078, 0.4922, 0.0000, 0.0000, 0.0000},
			{0.1494, 0.6250, 0.2266, 0.0000, 0.0000},
			{0.2432, 0.4688, 0.1167, 0.1719, 0.0000},
			{0.0618, 0.3535, 0.1611, 0.3379, 0.0859},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.4062, 0.5938, 0.0000, 0.0000, 0.0000},
			{0.2178, 0.3945, 0.3887, 0.0000, 0.0000},
			{0.1562, 0.2354, 0.3145, 0.2930, 0.0000},
			{0.1099, 0.1855, 0.2393, 0.2500, 0.2139},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.2480, 0.7539, 0.0000, 0.0000, 0.0000},
			{0.2812, 0.5039, 0.2158, 0.0000, 0.0000},
			{0.1211, 0.2148, 0.4551, 0.2080, 0.0000},
			{0.1748, 0.2139, 0.1572, 0.3027, 0.1523},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.9844, 0.0153, 0.0000, 0.0000, 0.0000},
			{0.4570, 0.0068, 0.5352, 0.0000, 0.0000},
			{0.4805, 0.0062, 0.4805, 0.0327, 0.0000},
			{0.3125, 0.0049, 0.3125, 0.0245, 0.3438},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5352, 0.4648, 0.0000, 0.0000, 0.0000},
			{0.2520, 0.4160, 0.3320, 0.0000, 0.0000},
			{0.3438, 0.2314, 0.2500, 0.1748, 0.0000},
			{0.1069, 0.1807, 0.1953, 0.2119, 0.3047},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.4160, 0.5820, 0.0000, 0.0000, 0.0000},
			{0.4297, 0.4375, 0.1318, 0.0000, 0.0000},
			{0.3809, 0.3379, 0.1089, 0.1729, 0.0000},
			{0.3320, 0.2656, 0.1377, 0.1914, 0.0723},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.2139, 0.7852, 0.0000, 0.0000, 0.0000},
			{0.1055, 0.0752, 0.8203, 0.0000, 0.0000},
			{0.1187, 0.0214, 0.1729, 0.6875, 0.0000},
			{0.0967, 0.0055, 0.0752, 0.0952, 0.7266},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.3770, 0.6211, 0.0000, 0.0000, 0.0000},
			{0.2373, 0.1338, 0.6289, 0.0000, 0.0000},
			{0.3281, 0.1836, 0.0645, 0.4238, 0.0000},
			{0.2461, 0.0713, 0.0508, 0.0649, 0.5664},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.6992, 0.2988, 0.0000, 0.0000, 0.0000},
			{0.6328, 0.3340, 0.0322, 0.0000, 0.0000},
			{0.4453, 0.3633, 0.0325, 0.1592, 0.0000},
			{0.3086, 0.3809, 0.0398, 0.2490, 0.0225},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.4863, 0.5117, 0.0000, 0.0000, 0.0000},
			{0.3535, 0.4180, 0.2285, 0.0000, 0.0000},
			{0.2773, 0.3164, 0.1904, 0.2148, 0.0000},
			{0.2344, 0.2559, 0.1562, 0.1973, 0.1553},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.1055, 0.8945, 0.0000, 0.0000, 0.0000},
			{0.0591, 0.4492, 0.4922, 0.0000, 0.0000},
			{0.0430, 0.2637, 0.3477, 0.3457, 0.0000},
			{0.0265, 0.1064, 0.1562, 0.2539, 0.4590},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.6289, 0.3711, 0.0000, 0.0000, 0.0000},
			{0.4434, 0.1934, 0.3633, 0.0000, 0.0000},
			{0.5859, 0.1885, 0.1719, 0.0547, 0.0000},
			{0.4688, 0.1729, 0.1094, 0.0586, 0.1904},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.7695, 0.2305, 0.0000, 0.0000, 0.0000},
			{0.6133, 0.1309, 0.2578, 0.0000, 0.0000},
			{0.3105, 0.1250, 0.2832, 0.2832, 0.0000},
			{0.3867, 0.0771, 0.1455, 0.1738, 0.2168},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.9844, 0.0162, 0.0000, 0.0000, 0.0000},
			{0.9648, 0.0245, 0.0101, 0.0000, 0.0000},
			{0.9336, 0.0339, 0.0181, 0.0145, 0.0000},
			{0.9258, 0.0232, 0.0217, 0.0127, 0.0173},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.2188, 0.7812, 0.0000, 0.0000, 0.0000},
			{0.0527, 0.1670, 0.7812, 0.0000, 0.0000},
			{0.1069, 0.1543, 0.7188, 0.0205, 0.0000},
			{0.1211, 0.1191, 0.5703, 0.0198, 0.1709},
		},

		{
			{1.0000, 0.0000, 0.0000, 0.0000, 0.0000},
			{0.5781, 0.4219, 0.0000, 0.0000, 0.0000},
			{0.2656, 0.5977, 0.1387, 0.0000, 0.0000},
			{0.2100, 0.2451, 0.2188, 0.3262, 0.0000},
			{0.1475, 0.1279, 0.1240, 0.4316, 0.1699},
		},
	}

	actualScores32, err := actualScores.ToFloat32() // shape=[32,5,5] dtype=DT_F32
	if err != nil {
		t.Fatal(err)
	}
	if actualScores32, err = ml.Softmax(actualScores32, len(actualScores32.Size)-1); err != nil { // shape=[32,5,5] dtype=DT_F32
		t.Fatal(err)
	}
	if actualScores, err = actualScores32.ToBFloat16(); err != nil { // shape=[32,5,5] (N_Heads, sequenceLength, sequenceLength) dtype=DT_BF16
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedScoresSoftmax, expectedScoresSoftmaxSize, actualScores, 2*common.THRESHOLD_BF16, false); err != nil {
		t.Fatal(err)
	}

	/*
		Goal in Python manner:
		output = torch.matmul(scores, values)
		output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)
	*/

	expectedOutputBeforeWeightsSize := []int{5, 4096}
	expectedOutputBeforeWeights := [][]float32{
		{-0.0060, -0.0064, 0.0056 /*...,*/, 0.0015, -0.0007, -0.0014},
		{-0.0059, -0.0064, 0.0054 /*...,*/, 0.0014, -0.0045, 0.0009},
		{-0.0052, -0.0062, 0.0053 /*...,*/, 0.0011, -0.0031, 0.0024},
		{-0.0027, -0.0058, 0.0081 /*...,*/, 0.0006, 0.0013, -0.0002},
		{-0.0025, -0.0041, 0.0049 /*...,*/, 0.0005, 0.0012, -0.0006},
	}

	actualOutput, err := ml.MatMul(actualScores, actualValues)
	if err != nil {
		t.Fatal(err)
	}
	if actualOutput, err = actualOutput.Transpose(0, 1); err != nil {
		t.Fatal(err)
	}
	outputTrailingSize := actualOutput.GetElementCount() / sequenceLength
	if actualOutput, err = actualOutput.Reshape([]int{sequenceLength, outputTrailingSize}); err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedOutputBeforeWeights, expectedOutputBeforeWeightsSize, actualOutput, common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	expectedOutputAfterWeightsSize := []int{5, 4096}
	expectedOutputAfterWeights := [][]float32{
		{-0.0275, -0.0413, -0.0193 /*...,*/, 0.0128, -0.0044, 0.0304},
		{-0.0261, -0.0098, -0.0171 /*...,*/, 0.0132, -0.0055, 0.0096},
		{-0.0145, -0.0057, -0.0008 /*...,*/, 0.0100, 0.0041, 0.0197},
		{-0.0114, -0.0042, -0.0073 /*...,*/, 0.0056, -0.0028, 0.0099},
		{-0.0152, -0.0109, -0.0070 /*...,*/, 0.0002, 0.0088, 0.0193},
	}

	/*
		Apply lat.attn_wo weights to output
	*/

	// lat.attn_wo: [out_features, in_features] -> shape: [4096 4096] -> [N_Heads * HeadDim, Dim]
	if actualOutput, err = ml.LinearTransformation(actualOutput, attention.attn_wo); err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedOutputAfterWeights, expectedOutputAfterWeightsSize, actualOutput, common.THRESHOLD_BF16, true); err != nil {
		t.Fatal(err)
	}

	return actualOutput
}

func testTransformerBlock_FeedForward_Forward(t *testing.T, skipCompareTestTensor bool, context *InferenceContext, feedForward *LlamaFeedForward, x *ml.Tensor) *ml.Tensor {
	/*
		Goal in Python manner:
		self.w2(F.silu(self.w1(x)) * self.w3(x))
		-->
		self.ffn_down(F.silu(self.ffn_gate(x)) * self.ffn_up(x))
	*/
	h, err := ml.LinearTransformation(x, feedForward.ffn_gate)
	if err != nil {
		t.Fatal(err)
	}
	if h, err = ml.Silu(h); err != nil {
		t.Fatal(err)
	}
	ffnUpX, err := ml.LinearTransformation(x, feedForward.ffn_up)
	if err != nil {
		t.Fatal(err)
	}
	if h, err = ml.MultiplyElementwise(h, ffnUpX); err != nil {
		t.Fatal(err)
	}
	actualOutput, err := ml.LinearTransformation(h, feedForward.ffn_down)
	if err != nil {
		t.Fatal(err)
	}
	return actualOutput
}

func testTransformerBlock_Forward(t *testing.T, skipCompareTestTensor bool, context *InferenceContext, transformerBlock *LlamaTransformerBlock, x *ml.Tensor, startPos int, freqsCis *ml.Tensor, mask *ml.Tensor) *ml.Tensor {
	/*
		h, err := ltb.attention.Forward(context, normalizedX, startPos, freqsCis, mask)
	*/
	normalizedX := testTransformerBlock_AttnNorm_Forward(t, skipCompareTestTensor, transformerBlock, x)
	h := testTransformerBlock_Attention_Forward(t, skipCompareTestTensor, context, transformerBlock.attention, normalizedX, startPos, freqsCis, mask)

	expectedHBeforeFeedForwardSize := []int{5, 4096}
	expectedHBeforeFeedForward := [][]float32{
		{-0.0256, -0.0447, -0.0189 /*...,*/, 0.0045, -0.0018, 0.0265},
		{0.0120, -0.0104, -0.0103 /*...,*/, -0.0036, -0.0031, 0.0254},
		{-0.0294, -0.0220, 0.0102 /*...,*/, 0.0183, -0.0242, 0.0245},
		{-0.0145, -0.0143, -0.0183 /*...,*/, 0.0023, -0.0066, -0.0017},
		{-0.0206, -0.0097, 0.0013 /*...,*/, 0.0114, 0.0045, 0.0116},
	}

	var err error
	if h, err = ml.Add(x, h); err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedHBeforeFeedForward, expectedHBeforeFeedForwardSize, h, common.THRESHOLD_BF16, true); err != nil {
		t.Error(err)
	}

	/*
		h, err = ltb.ffn_norm.Forward(context, h)
	*/
	expectedOutputSize := []int{5, 4096}
	expectedOutput := [][]float32{
		{-0.0308, 0.0505, -0.0298 /*...,*/, -0.0136, -0.0266, 0.0674},
		{0.0486, 0.0176, -0.0102 /*...,*/, 0.0339, -0.0004, 0.0342},
		{-0.0299, -0.0190, 0.0240 /*...,*/, 0.0243, -0.0422, 0.0386},
		{-0.0120, -0.0110, -0.0449 /*...,*/, 0.0095, 0.0035, -0.0093},
		{-0.0146, -0.0078, 0.0127 /*...,*/, 0.0147, 0.0116, 0.0124},
	}
	normalizedH, err := transformerBlock.ffn_norm.Forward(context, h)
	if err != nil {
		t.Fatal(err)
	}
	ffnOutput := testTransformerBlock_FeedForward_Forward(t, skipCompareTestTensor, context, transformerBlock.feedForward, normalizedH)
	actualOutput, err := ml.Add(h, ffnOutput)
	if err != nil {
		t.Fatal(err)
	}
	if err := ml.CompareTestTensorSkippable(skipCompareTestTensor, expectedOutput, expectedOutputSize, actualOutput, common.THRESHOLD_BF16, true); err != nil {
		t.Error(err)
	}
	return actualOutput
}

func testTransformer_Forward(t *testing.T, onlyFirstLayer bool, context *InferenceContext, transformer *LlamaTransformer) {
	// tokens: "<BOS>My name is"
	tokens := []TokenId{1, 15043, 590, 1024, 338}
	startPos := 0

	actualInputTensor, actualFreqsCis, actualMask, err := transformer.prepare(tokens, startPos)
	if err != nil {
		t.Error(err)
	}
	testTransformer_Prepare(t, actualInputTensor, actualFreqsCis, actualMask)

	currentTensor := actualInputTensor
	if onlyFirstLayer {
		firstLayer := transformer.Layers[0]
		testTransformerBlock_Forward(t, false, context, firstLayer, currentTensor, startPos, actualFreqsCis, actualMask)
	} else {
		fmt.Println()
		for layerIdx, layer := range transformer.Layers {
			fmt.Printf("Running transformer block layer: %d / %d\n", layerIdx+1, len(transformer.Layers))
			currentTensor = testTransformerBlock_Forward(t, true, context, layer, currentTensor, startPos, actualFreqsCis, actualMask)
		}
	}
}

func testSimulatedInternal(t *testing.T, onlyFirstLayer bool) {
	modelFilePath := "../../models-original/7B/consolidated.00.pth"
	if _, err := os.Stat(modelFilePath); err != nil {
		t.Skipf("Model file \"%s\" is not found, passing this test: %s", modelFilePath, "TestSimulated")
		return
	}
	llamaModel, err := LoadModel(modelFilePath)
	if err != nil {
		t.Error(err)
	}

	inferenceArgs := common.NewInferenceArgs()
	inferenceArgs.Seed = 1234
	inferenceArgs.SequenceLength = 8
	context := NewInferenceContext(llamaModel, inferenceArgs)
	testTransformer_Forward(t, onlyFirstLayer, context, llamaModel.Transformer)
	llamaModel.Free()
}

func TestSimulatedOnlyFirstLayer(t *testing.T) {
	testSimulatedInternal(t, true)
}

const runTestSimulatedFull = false

func TestSimulatedFull(t *testing.T) {
	if !runTestSimulatedFull {
		t.Skip("Skipping TestSimulatedFull because runTestSimulatedFull is set to false")
	}
	testSimulatedInternal(t, false)
}
